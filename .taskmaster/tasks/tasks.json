{
  "master": {
    "tasks": [
      {
        "id": 20,
        "title": "Project setup, environment parity, and secure config baseline",
        "description": "Establish a reproducible local environment matching Vercel+Neon, standardize environment variables, logging, and dependency updates to enable debugging and fixes, and add missing API endpoints/database functions uncovered by investigation. Emphasize comprehensive testing: no subtask is complete until all testing is verified in both local and production environments, including command-line (PowerShell Invoke-WebRequest), BrowserMCP browser testing, database verification, local environment checks, and production deployment verification.",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "details": "- Node.js LTS 20.x; update dependencies with npm-check-updates and run npm audit fix (review breaking changes).\n- Ensure pg@8.x with connection pooling via pg.Pool; configure Neon pooled connection string (pgBouncer) for production; use DATABASE_URL, JWT_SECRET, SESSION_SECRET, COOKIE_SECURE, VERCEL envs.\n- Add dotenv-flow for layered envs (.env.local, .env.production). Do not commit secrets.\n- Integrate pino@9 for structured logging; add pino-http middleware in Express OR adapt existing custom logger to emit pino-compatible JSON. Central error handler returns standardized JSON {error, code}.\n- CORS and helmet@7 for security; express-rate-limit for auth and admin-sensitive routes.\n- Configure Prisma or continue with node-postgres: if current code uses raw pg, retain it; add sql template tag for parameterized queries to prevent injection.\n- Add Zod@3 for request validation; create middleware validate(schema) for API inputs.\n- Add linting/formatting: eslint@9, typescript@5 if repo uses TS; otherwise JSDoc types.\n- Dev DB: local Postgres 15/16 with same schema as Neon; run migrations. Add seed script for test users, roles, and sample content.\n- Vercel: ensure serverless functions timeouts respected; move long-running tasks to background or edge config as needed.\n- Logging for production via pino transport to Vercel logs; mask PII; never log SSNs.\n- Implement missing API endpoints and DB functions discovered:\n  • Volunteers: PUT /api/volunteers/:id with updateVolunteer(id, payload) using parameterized queries; validate allowed fields with Zod; enforce role-based authorization.\n  • News: POST /api/news/:id/publish, PUT /api/news/:id, DELETE /api/news/:id (soft delete via deleted_at), and corresponding DB functions publishNews, updateNews, deleteNewsSoft; ensure slug uniqueness and updated_at handling.\n  • Links/Resources: Full CRUD: GET /api/links, GET /api/links/:id, POST /api/links, PUT /api/links/:id, DELETE /api/links/:id with DB functions listLinks, getLink, createLink, updateLink, deleteLink; include ordering and visibility flags.\n  • Insurance Forms: Review and correct field mapping in API to expected keys {club, eventName, eventDate, eventDescription}; map club -> club_id; ensure ISO 8601 dates and server-side validation.\n  • Admin Login: Audit and harden authentication; verify JWT/session configuration, secrets, cookie flags; ensure roles/permissions lookups; add rate limiting and brute-force protection to /api/auth/login.\n  • Backup Management: Add admin API for backups (e.g., POST /api/admin/backups to trigger, GET /api/admin/backups to list, GET /api/admin/backups/:id/download) with strict admin-only access; stub UI endpoints and integrate with Neon logical backups or S3 if available.\n  • Content Management: PUT /api/clubs/:id/description to update description safely with sanitization and cache revalidation.\n\nTesting policy for all subtasks:\n- No subtask can be marked complete until all of the following pass in both local and production: (1) PowerShell Invoke-WebRequest command-line tests, (2) Browser testing using BrowserMCP tools, (3) Direct database verification of persistence and constraints, (4) Local environment validation including env/config and serverless constraints, (5) Production deployment verification on Vercel+Neon with logs free of PII.",
        "testStrategy": "- Global verification applicable to all subtasks (must pass in both local and production before completion):\n  1) Command line testing (PowerShell): use Invoke-WebRequest and Invoke-RestMethod to exercise endpoints with headers/auth, capture status codes and bodies, and validate CORS and rate limits.\n  2) Browser testing (BrowserMCP): execute GET/POST/PUT/DELETE flows, validate UI states, auth redirects, and cache revalidation; confirm no mixed content or CSP violations.\n  3) Database verification: connect to local Postgres and Neon; verify rows created/updated/deleted as expected, soft deletes set deleted_at, updated_at modified, constraints enforced (unique slug, FKs), and audit logs where applicable.\n  4) Local environment testing: NODE_ENV=development with dotenv-flow; run migrations/seed; confirm SELECT 1, pooled connections, structured logging, rate limits, and serverless behavior simulated if applicable.\n  5) Production deployment verification: deploy to Vercel; confirm endpoints function under timeouts, Neon connectivity, logs via pino, envs configured, secrets set, and no PII in logs.\n- Existing coverage remains: env loading, DB connectivity, lint/tests in CI, security scans, endpoint coverage, and E2E smoke, all extended to include the five required testing categories.",
        "subtasks": [
          {
            "id": 1,
            "title": "Add Volunteer update endpoint and DB function",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "- Implement PUT /api/volunteers/:id with Zod validation and role-based authorization (admin/club_admin).\n- Create updateVolunteer(pool, id, data) using parameterized SQL; whitelist updatable fields (e.g., status, notes, assigned_club_id).\n- Return 204 on success; 404 if volunteer not found; audit log the change.\n<info added on 2025-08-12T04:54:59.769Z>\nCOMPLETED: Volunteer status update implemented.\n\n- Database: added columns status (VARCHAR(50), default 'pending'), notes (TEXT), assigned_club_id (UUID) with index on status via migration database/add-volunteer-status.js.\n- DB function: updateVolunteer(volunteerId, updates) in database/neon-functions.js with field whitelist ['status','notes','assigned_club_id'], parameterized queries, returns updated row or null; exported.\n- API: PUT /api/volunteers/:id in api/index.js; validates status ['pending','contacted','confirmed','declined']; 404 if not found; 400 for invalid status; 500 on server error; wired to updateVolunteer.\n- Security: whitelisting, parameterized queries, input validation, and error logging in place.\n</info added on 2025-08-12T04:54:59.769Z>\n\nTesting requirements (must pass locally and in production before completion):\n- PowerShell: Invoke-WebRequest -Method Put -Uri \"$ENV:BASE_URL/api/volunteers/$id\" -Headers @{Authorization=\"Bearer $token\"} -ContentType 'application/json' -Body (@{status='confirmed'} | ConvertTo-Json) | Select-Object StatusCode\n- BrowserMCP: Perform authenticated PUT via UI/admin panel; verify success toast and updated status in list; check network tab for 204.\n- Database: SELECT status, notes, assigned_club_id FROM volunteers WHERE id = $1; verify changes and updated_at; ensure audit log entry present.\n- Local env: .env.local loaded; Zod errors return 400; rate limit not triggered under normal use; logs structured (pino) without PII.\n- Production: Vercel deploy; Neon connection via pgBouncer; confirm 204 responses, 404 for missing, 400 for invalid; review Vercel logs for masked PII.",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement News publish/edit/delete API and SQL",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "- Add endpoints: POST /api/news/:id/publish, PUT /api/news/:id, DELETE /api/news/:id (soft delete).\n- Ensure slug uniqueness, updated_at optimistic concurrency, and role checks.\n- DB functions: publishNews, updateNews, deleteNewsSoft; add updated_at trigger if missing.\n\nTesting requirements (must pass locally and in production before completion):\n- PowerShell:\n  • PUT: Invoke-WebRequest -Method Put -Uri \"$ENV:BASE_URL/api/news/$id\" -Headers @{Authorization=\"Bearer $token\";'If-Match'=$etag} -ContentType 'application/json' -Body (@{title='New';slug='unique-slug'}|ConvertTo-Json)\n  • DELETE: Invoke-WebRequest -Method Delete -Uri \"$ENV:BASE_URL/api/news/$id\" -Headers @{Authorization=\"Bearer $token\"}\n  • PUBLISH: Invoke-WebRequest -Method Post -Uri \"$ENV:BASE_URL/api/news/$id/publish\" -Headers @{Authorization=\"Bearer $token\"}\n- BrowserMCP: Edit and delete via admin UI; verify publish sets status and published_at; ensure deleted items hidden from public lists.\n- Database: Verify slug uniqueness constraint; deleted_at set on soft delete; updated_at changed; published_at set on publish; optional audit rows.\n- Local env: Validate role checks, Zod validation, rate limiting on admin routes; structured logs.\n- Production: Test flows on Vercel with Neon; confirm ETag/updated_at concurrency works; review logs and ensure no PII.",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Build Links/Resources CRUD API and DB layer",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "- Endpoints: GET /api/links, GET /api/links/:id, POST /api/links, PUT /api/links/:id, DELETE /api/links/:id.\n- Fields: title, url, category, order_index, is_visible; validate and sanitize.\n- DB: listLinks, getLink, createLink, updateLink, deleteLink; support ordering.\n\nTesting requirements (must pass locally and in production before completion):\n- PowerShell:\n  • POST: Invoke-RestMethod -Method Post -Uri \"$ENV:BASE_URL/api/links\" -Headers @{Authorization=\"Bearer $token\"} -ContentType 'application/json' -Body (@{title='Site';url='https://example.com';category='general';order_index=1;is_visible=$true}|ConvertTo-Json)\n  • GET list/item, PUT update, DELETE remove using Invoke-WebRequest/Invoke-RestMethod and assert status codes 200/201/204.\n- BrowserMCP: Create, edit, reorder, toggle visibility; verify ordering in list and visibility on public page.\n- Database: Check rows inserted/updated; ordering maintained; constraints on URL format if enforced; soft delete policy if applicable.\n- Local env: Validate schema errors; ensure sanitization; ensure pagination/performance acceptable; logs structured.\n- Production: Verify CRUD under serverless timeouts; confirm Vercel logs and Neon pooling; no PII in logs.",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Fix Insurance Forms field mapping and validation",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "- Align API parsing with expected keys {club, eventName, eventDate, eventDescription}; convert eventDate to ISO; map club -> club_id.\n- Add Zod schema and return detailed 400/422 errors; prevent duplicates via idempotency key or unique constraint.\n\nTesting requirements (must pass locally and in production before completion):\n- PowerShell: Invoke-RestMethod -Method Post -Uri \"$ENV:BASE_URL/api/insurance/events\" -ContentType 'application/json' -Body (@{club='orchestra';eventName='Fall Concert';eventDate='2025-10-01T19:00:00Z';eventDescription='Annual'}|ConvertTo-Json) | Should -Not -BeNullOrEmpty\n- BrowserMCP: Submit form with valid and invalid data; verify field-level errors and disabled submit during pending; ensure success shows in admin view.\n- Database: Confirm club_id mapping via lookup; record persisted with ISO date; uniqueness/idempotency respected; verify created_at/updated_at.\n- Local env: Ensure express.json parsing, Zod validation, and correct 400/422 codes; logs structured and free of PII.\n- Production: Verify endpoint returns 201; duplicates prevented on double submit; Neon write visible in admin UI.",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Audit and harden Admin Login (sessions/JWT)",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "- Verify auth mechanism (session vs JWT), secrets, cookie flags (Secure, HttpOnly, SameSite), token expiry.\n- Ensure password hashing with bcrypt@5; parameterized user+roles lookup; lockout/brute-force protection on /api/auth/login.\n\nTesting requirements (must pass locally and in production before completion):\n- PowerShell: Invoke-RestMethod -Method Post -Uri \"$ENV:BASE_URL/api/auth/login\" -ContentType 'application/json' -Body (@{email='admin@example.com';password='P@ssw0rd'}|ConvertTo-Json) | Select-Object token, sessionId\n- BrowserMCP: Login as admin, club_admin, and regular user; verify role-based access to /admin routes; confirm logout clears session/JWT.\n- Database: Verify bcrypt hashes stored; roles/user_roles mappings correct; failed attempts increment and lockout thresholds enforced.\n- Local env: Check cookie flags in dev over HTTPS; JWT signing with JWT_SECRET; rate limiting and brute-force protections active.\n- Production: Verify secure cookies (Secure, HttpOnly, SameSite), token expiry, refresh if implemented; review Vercel logs for auth events without PII.",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Add Backup Management admin APIs",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "- Create POST /api/admin/backups (trigger), GET /api/admin/backups (list), GET /api/admin/backups/:id/download (download) with admin-only authorization.\n- Integrate with Neon backups or S3 if configured; otherwise no-op stub in dev with clear responses.\n\nTesting requirements (must pass locally and in production before completion):\n- PowerShell:\n  • Trigger: Invoke-WebRequest -Method Post -Uri \"$ENV:BASE_URL/api/admin/backups\" -Headers @{Authorization=\"Bearer $token\"}\n  • List: Invoke-RestMethod -Method Get -Uri \"$ENV:BASE_URL/api/admin/backups\" -Headers @{Authorization=\"Bearer $token\"}\n  • Download: Invoke-WebRequest -Method Get -Uri \"$ENV:BASE_URL/api/admin/backups/$id/download\" -OutFile backup.dump -Headers @{Authorization=\"Bearer $token\"}\n- BrowserMCP: Trigger backup from admin UI and download artifact; verify appropriate messages in non-prod (stub).\n- Database: If using logical backups metadata table, verify entry creation; otherwise validate S3 object existence.\n- Local env: Stubbed responses function with clear messaging; auth enforced; rate limits applied.\n- Production: Confirm admin-only access; successful trigger/list/download; verify storage location and retention; logs contain no sensitive data.",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Add Content Description update API",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "- Implement PUT /api/clubs/:id/description with sanitization and length limits; authorize admin/club_admin; trigger homepage cache revalidation.\n\nTesting requirements (must pass locally and in production before completion):\n- PowerShell: Invoke-WebRequest -Method Put -Uri \"$ENV:BASE_URL/api/clubs/$id/description\" -Headers @{Authorization=\"Bearer $token\"} -ContentType 'application/json' -Body (@{description='Safe <b>update</b>'}|ConvertTo-Json)\n- BrowserMCP: Update description via admin UI; verify preview debounce, sanitize output, and homepage reflects after revalidation.\n- Database: Verify description updated, sanitized; updated_at changed; only authorized roles can modify.\n- Local env: Ensure validation rejects overly long input; XSS sanitized; revalidation hook called.\n- Production: Verify change visible on homepage; cache revalidation succeeds; logs structured with no PII.",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 21,
        "title": "Fix Admin Login and role-based access for Booster Club Admins",
        "description": "Resolve inability for booster club admins to sign in and access admin panel with proper roles/permissions.",
        "details": "- Audit auth flow: if using sessions, ensure express-session with secure cookies behind HTTPS; if JWT, ensure sign/verify using HS256 and JWT_SECRET.\n- Check users table, roles/permissions tables (e.g., roles, user_roles, clubs). Ensure booster admins (e.g., orchestra_booster) exist and are active; passwords hashed with bcrypt@5 (bcrypt.hash(password, 12)).\n- Implement login endpoint POST /api/auth/login validating {username/email, password}; parameterized query to get user and roles; compare bcrypt.\n- Issue session or JWT; include role claims and club_id for scoping.\n- Middleware requireAuth and requireRole(['admin','club_admin']); verify role and optionally club scope.\n- Fix admin panel route protection to accept club_admin as authorized.\n- Ensure CSRF protection for cookie-based sessions via csurf or use double-submit token; for JWT add SameSite=Lax cookies if using httpOnly.\nPseudo:\nconst user = await db.one('SELECT id,password_hash FROM users WHERE username=$1', [u]);\nif(!await bcrypt.compare(pw,user.password_hash)) throw 401;\nconst roles = await db.many('SELECT r.name FROM roles r JOIN user_roles ur ON ur.role_id=r.id WHERE ur.user_id=$1',[user.id]);\nconst token = jwt.sign({sub:user.id, roles, clubId}, process.env.JWT_SECRET, {expiresIn:'8h'});\n",
        "testStrategy": "- Create test accounts: global admin, club_admin(orchestra), regular user.\n- Unit: successful login returns token/session; wrong password returns 401; locked/inactive user blocked.\n- E2E: club_admin can access /admin routes; regular user cannot.\n- Security: tokens expire; refresh flow if implemented; cookies httpOnly/SameSite; brute-force lockout after N attempts with rate-limit.",
        "priority": "high",
        "dependencies": [
          20
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 22,
        "title": "Repair Volunteer Status Update in Admin Dashboard",
        "description": "Fix API and DB logic causing 'Volunteer Not found' when updating volunteer submission status.",
        "details": "- Identify endpoint (e.g., PATCH /api/volunteers/:id/status). Inspect frontend to confirm payload {id,status,notes?}.\n- Validate payload with Zod: id as UUID/int, status in ['pending','approved','rejected','inactive'].\n- DB query must use correct table and primary key; verify volunteers table schema and foreign keys (user_id, club_id). Ensure ID from UI matches DB id (not submission id vs user id mismatch).\n- Use parameterized update returning rowCount to detect missing records. If club scoping applies, include club_id in WHERE when club admins update.\n- Add 404 when not found; 409 if invalid transition; 200 with updated record on success.\n- Consider transaction if updating related audit log table volunteer_status_history.\n- Frontend: ensure button triggers fetch with method PATCH, correct URL, credentials, CSRF/JWT headers; display toast on success/error.\nSQL:\nUPDATE volunteers SET status=$1, updated_at=NOW() WHERE id=$2 RETURNING id,status;\n",
        "testStrategy": "- Unit: status transitions valid; invalid status rejected with 400.\n- E2E: admin updates status from dashboard; verify DB row updated; history row inserted if applicable.\n- Negative: wrong id -> 404; mismatched club scope -> 403.\n- Regression: ensure listing volunteers still paginates and filters.",
        "priority": "high",
        "dependencies": [
          21
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 23,
        "title": "Restore News Publish functionality",
        "description": "Make 'Publish News' button functional including API, validation, and UI feedback.",
        "details": "- Frontend: attach click/submit handler to publish button; ensure form data {title, body, publish_at?, author_id, club_id?}. Disable button while request in-flight; show success/error toast.\n- API: POST /api/news with validation; sanitize HTML body using sanitize-html to prevent XSS if rich text.\n- DB: news table columns (id, title, body, status ['draft','published'], publish_at, author_id, club_id, created_at). Insert with status='published' and publish_at=NOW() or scheduled if provided.\n- Ensure role check: admin/club_admin can publish; scope by club if needed.\n- Return created news; revalidate any statically rendered pages if using ISR by calling Vercel revalidate endpoint.\n- Add indexes on (status, publish_at DESC) for front-page queries.\n",
        "testStrategy": "- Unit: validation rejects missing title/body; XSS payloads sanitized.\n- E2E: clicking Publish creates visible item on public news feed; check SSR/ISR revalidation if applicable.\n- Permissions: regular user blocked; club_admin can publish within club scope.\n- Regression: drafts unaffected.",
        "priority": "high",
        "dependencies": [
          21,
          20
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 24,
        "title": "Fix News Edit and Delete operations",
        "description": "Enable editing and deletion of existing news items via functional endpoints and UI handlers. Backend API and database operations are complete and verified; Delete UI is complete; Edit UI still needs replacing the placeholder alert with a proper edit form/modal.",
        "status": "done",
        "dependencies": [
          23
        ],
        "priority": "high",
        "details": "- Backend/API: COMPLETE. PUT /api/news/:id validates and updates mutable fields; DELETE /api/news/:id performs soft delete (deleted_at) to preserve history; database functions updateNews() and deleteNews() are implemented and functional; slug uniqueness handled if applicable; updated_at trigger in place.\n- Frontend Delete: IMPLEMENTED. Delete button triggers confirmation dialog and calls DELETE /api/news/:id; deleted items no longer appear in lists.\n- Frontend Edit: PARTIAL. Edit button currently shows a placeholder alert. Needs modal/form populated via GET /api/news/:id, with save to PUT /api/news/:id and optimistic UI feedback.\n- Authorization: only author, admin, or club_admin of same club can edit/delete.\n- DB: Soft delete via deleted_at; updated_at maintained; optional audit table news_changes(user_id, news_id, diff jsonb, changed_at) remains optional.",
        "testStrategy": "- API/DB: VERIFIED. PUT and DELETE endpoints tested successfully including updates to title, content, and status; delete hides items from lists. Verified via database-backed functions updateNews() and deleteNews().\n- Unit: Keep coverage for invalid ID -> 404; missing permissions -> 403; optimistic concurrency via updated_at/If-Match if enabled.\n- E2E: Delete flow fully passes (confirmation + absence from public lists). Edit flow pending UI form implementation: add tests to ensure modal loads data via GET /api/news/:id and saving persists via PUT.\n- Regression: Publish flow remains functional; no regressions observed in news listing after deletions.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement and verify backend edit and delete endpoints",
            "description": "Ensure PUT /api/news/:id and DELETE /api/news/:id are implemented with validation, authorization, and soft delete behavior; include database functions updateNews() and deleteNews().",
            "status": "completed",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Wire up Delete UI with confirmation",
            "description": "Connect delete buttons to call DELETE /api/news/:id with a confirmation dialog and refresh the list to exclude deleted items.",
            "status": "completed",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Replace Edit UI placeholder with modal form",
            "description": "Replace the current alert placeholder for the Edit action with a modal/form. On open, fetch data via GET /api/news/:id to populate fields; on save, call PUT /api/news/:id and show success/error feedback.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Add E2E tests for Edit UI flow",
            "description": "Add tests to verify the edit modal opens, loads existing data, saves changes via PUT, and updates the UI. Ensure delete E2E tests remain passing.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 25,
        "title": "Repair Links & Resources CRUD",
        "description": "Links & Resources CRUD is fully implemented end-to-end with validation, security, and UI feedback across add, edit, delete, and public view.",
        "status": "done",
        "dependencies": [
          21,
          20
        ],
        "priority": "medium",
        "details": "- Frontend: Add and edit forms use proper <form> with onsubmit handlers, real-time URL validation, required title and URL, disabled button states during submission, and unified showAlert() UX. Edit uses a dynamic modal with pre-populated fields, preserves validation, and includes a visibility toggle. Delete has confirmation, feedback via showAlert, and automatic data refresh.\n- Public Page: links.html loads visible links from /api/links/visible with loading/error states, tracks clicks via /api/links/:id/click, secures external links with rel=\"noopener noreferrer\", and escapes user-generated content for XSS protection. Status and category badges, responsive layout, accessibility (ARIA, keyboard), and clear loading states included.\n- API: CRUD endpoints operational: GET /api/links (admin), GET /api/links/visible (public), POST /api/links, PUT /api/links/:id, DELETE /api/links/:id, and POST /api/links/:id/click for click tracking. Parameterized queries with backend URL validation, input sanitization, and proper error handling. Unique(title, club_id) enforced if configured; sort order maintained.\n- DB: links table includes id, title, url, description, club_id, position, visibility, created_at, updated_at; index on (club_id, position) present. Seeded with 7 default links for immediate functionality.\n- Security & Roles: Sanitization applied to text fields; only admins/club_admins can mutate; public endpoints expose only visible fields.",
        "testStrategy": "- Unit: Frontend and backend reject invalid URLs; duplicate title returns 409; visibility toggle persists; showAlert displays correct messages. Backend sanitization and role checks covered.\n- Integration/API: Verified responses for GET /api/links (admin), GET /api/links/visible (public), POST /api/links, PUT /api/links/:id, DELETE /api/links/:id, and POST /api/links/:id/click.\n- E2E: Add link appears in list; edit persists and reflects in modal and list; delete removes and triggers list refresh; sort order maintained across operations; public links page loads dynamically without errors; click tracking increments counter.\n- Regression: Public links page renders on mobile/desktop without console errors; accessibility checks for modals and controls; ensure external links use rel attributes and escaped HTML.",
        "subtasks": []
      },
      {
        "id": 26,
        "title": "Fix Insurance Forms event submission",
        "description": "Completed: Fixed missing required fields error by correcting form structure, bindings, validation, and API parsing. Implemented proper form wrapper and submit handling, added required attributes, ensured submit button ID for E2E, enforced client and server validation, and confirmed API/DB flow.",
        "status": "done",
        "dependencies": [
          20,
          21
        ],
        "priority": "high",
        "details": "- Frontend:\n  - Wrapped insurance form elements in a proper <form id=\"insuranceForm\" onsubmit=\"submitInsuranceForm(event)\">.\n  - Ensured input names/IDs align with API expected keys: club, eventName, eventDate, eventDescription; values submitted via FormData with eventDate in ISO 8601.\n  - Added required attributes to insuranceEventName, insuranceEventDate, insuranceEventDescription, and ensured submit button has id=\"submitInsuranceBtn\" and type=\"submit\".\n  - Added client-side validation (Zod or native HTML5) and field-level error display; submit button disabled during pending submission to avoid double-clicks; re-enabled after completion.\n  - Updated submitInsuranceForm(event) to prevent default, serialize data, handle errors, and provide user feedback.\n- API:\n  - Verified POST /api/insurance/events parses body correctly (express.json and multer if files present).\n  - Validates required fields; maps club to club_id via lookup; stores event row and optionally sends email notification.\n- DB:\n  - insurance_events table (id, club_id, name, date, description, contact_id, created_at) verified; NOT NULL constraints align; defaults present.\n- Timezone:\n  - Store dates in UTC; display in local time consistently.\n- Files/locations updated:\n  - admin/dashboard.html (lines 677-728): form wrapper, required attributes, submit button id and handler.\n  - submitInsuranceForm() (lines 2056-2110): event handling, button disable/enable, improved error handling.",
        "testStrategy": "- Unit: missing fields -> 400 with details; valid submission -> 201; invalid date -> 422. All 47 insurance unit tests passing.\n- Integration: All 7 insurance integration tests passing; direct API calls verified with valid data.\n- E2E: Form elements discovered as expected (form id, submit button id); valid submission succeeds and record visible in admin view.\n- Regression: Double-clicks prevented by disabling submit button during submission.",
        "subtasks": []
      },
      {
        "id": 27,
        "title": "Restore Front Page Band Booster card rendering",
        "description": "Ensure Band booster card appears by fixing data fetch, conditions, and fallbacks.",
        "details": "- Confirm boosters query includes band club and status=active; check hidden flags. If filtering by has_officers or has_content, adjust to include band or fix underlying data.\n- Verify club slug mapping; ensure image/logo path valid; handle missing image fallback.\n- Frontend: conditional rendering should not short-circuit due to null description; default description from DB or copy.\n- If using server-side data fetch, ensure API returns band club; add index for clubs(active) to speed query.\n",
        "testStrategy": "- E2E: band card visible on homepage grid for anonymous users.\n- Data: toggling active flag hides/shows card as expected.\n- Performance: homepage loads within target time; no console errors.",
        "priority": "high",
        "dependencies": [
          23,
          24,
          25
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 28,
        "title": "Fix Content Management 'Update Description' for home cards",
        "description": "Wire up update description action to API and persist changes safely.",
        "details": "- Frontend: ensure textarea binds to state and submits PUT /api/clubs/:id/description with JSON {description}; debounce preview; show success toast.\n- API: validate description length and sanitize (allow basic formatting). Update clubs.description or club_cards.description.\n- Authorization: admin/club_admin for that club.\n- Invalidate/revalidate homepage cache after update.\n",
        "testStrategy": "- Unit: overly long input rejected; script tags stripped.\n- E2E: update reflects on homepage after revalidation.\n- Regression: other club cards unaffected.",
        "priority": "medium",
        "dependencies": [
          27,
          21
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 29,
        "title": "Backup Management page and API restoration",
        "description": "Recover missing/blank Backup Management in admin panel and ensure backups run safely.",
        "details": "- UI: restore admin route /admin/backups; render list of existing backups with actions (Create Backup, Download, Restore if allowed).\n- API: GET /api/backups (list), POST /api/backups (create), GET /api/backups/:id/download; Restrict to global admin only.\n- Implementation: for Neon, use logical backups via pg_dump run in serverless-compatible job: trigger Vercel Background Function or external job (GitHub Actions) to run pg_dump against DATABASE_URL and upload to secure storage (e.g., AWS S3 or Vercel Blob). For local, execute child_process pg_dump with allowlist of args.\n- Store backup metadata in backups table (id, filename, created_by, created_at, size). Do not implement DB restore from production in-app; provide instructions and link to run restore offline to mitigate risk.\n- Security: signed URLs for download with short TTL; encrypt at rest (SSE-S3) and in transit; never expose connection strings.\n",
        "testStrategy": "- E2E: page shows list; create backup triggers job and shows pending/completed status; download works with signed URL.\n- Negative: non-admin receives 403.\n- Operational: verify a created backup can be restored in staging manually.",
        "priority": "high",
        "dependencies": [
          21,
          20
        ],
        "status": "done",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-08-09T00:01:44.976Z",
      "updated": "2025-08-12T18:47:02.027Z",
      "description": "Tasks for master context"
    }
  },
  "feature-stripe-robotics-payment": {
    "tasks": [],
    "metadata": {
      "created": "2025-08-09T00:13:42.595Z",
      "updated": "2025-08-09T00:13:42.595Z",
      "description": "Stripe link + buy button on payment page for Eastlake Robotics Club"
    }
  },
  "security-audit": {
    "tasks": [
      {
        "id": 1,
        "title": "Initialize Project Repository and Environment",
        "description": "Project repository, environment configuration, Vercel deployment, and Neon PostgreSQL integration are fully set up and operational.",
        "details": "Repository initialized with proper structure, .env.local configured for local development, Vercel environment variables and vercel.json configured for production, Neon PostgreSQL connection established via environment variables, and Node.js/Express backend with static HTML frontend scaffolded. Package.json includes all required dependencies.",
        "testStrategy": "Verified repository initialization, environment variable loading, and successful Neon PostgreSQL connections in both local and Vercel environments. Confirmed production deployment and runtime health.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Design and Implement Database Schema & Migrations",
        "description": "Full PostgreSQL schema implemented with UUID PKs, FKs, indexes, triggers, and default admin users; migrations and integrity checks in place.",
        "details": "Implemented database/schema.sql with tables: officers, users, volunteers, insurance_forms, form_1099, documents. Added appropriate indexes and triggers, enforced referential integrity with UUID primary keys, and seeded default admin users. Schema reflects normalized design with performance-oriented indexing.",
        "testStrategy": "Migrations applied locally and on staging; validated referential integrity, rollback capability, index presence, and post-migration data consistency. Verified triggers and seed data creation.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Implement Role-Based Authentication & Authorization",
        "description": "Role-based authentication and authorization fully implemented with secure sessions and protected routes.",
        "details": "Implemented roles (admin, booster), secure login/logout, session management, and route protection with role checks. Admin panel with dynamic UI. Password validation and masking of sensitive fields in responses.",
        "testStrategy": "Tested login/logout flows, session expiration, CSRF-safe patterns on forms, and access restrictions per role. Attempted privilege escalation and verified denial on protected endpoints.",
        "priority": "high",
        "dependencies": [
          1,
          2
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Develop Booster Club CRUD APIs",
        "description": "RESTful endpoints for managing booster-related entities are implemented with validation, referential integrity, and authorization.",
        "details": "Implemented full CRUD operations for relevant booster/club entities and officers, including CSV import for bulk officer data, relationship management, and robust validation with parameterized queries. Enforced role-based access for Admin and Club Officers.",
        "testStrategy": "Unit and integration tests cover all CRUD operations, validation, referential integrity enforcement, and role restrictions. Verified error handling on invalid input.",
        "priority": "high",
        "dependencies": [
          2,
          3
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Develop Officer Management APIs & CSV Import",
        "description": "Officer CRUD APIs and CSV import with duplicate detection, PII validation, and club-specific management are complete.",
        "details": "Implemented GET/POST/PUT endpoints for officers and CSV import. Validated officer data (email, phone), sanitized PII, ensured SSN is never exposed in plaintext, and implemented server-side duplicate detection. Managed officer assignments to clubs with roles and date ranges.",
        "testStrategy": "Tested CRUD flows, input validation, CSV import with valid/invalid data, duplicate detection, and verified SSN masking. Confirmed club scoping and permissions.",
        "priority": "high",
        "dependencies": [
          2,
          3,
          4
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Develop Volunteer Signup & Management APIs",
        "description": "Volunteer signup and management APIs implemented with minimal PII collection, validation, and role-based access.",
        "details": "Implemented POST /api/volunteers and related GET endpoints. Added validation, limited PII to essentials, captured interests and availability, and enforced club association with role-based access controls.",
        "testStrategy": "Verified signup with valid/invalid data, ensured minimal PII storage, validated access controls and data visibility per role.",
        "priority": "medium",
        "dependencies": [
          2,
          3,
          4
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Implement 1099/W-9 Workflow APIs and Secure File Handling",
        "description": "1099 management, secure W-9 uploads via Vercel Blob, admin review tools, and CSV export are fully implemented.",
        "details": "Implemented GET /api/1099, POST /api/1099/upload-w9, and admin review endpoints. Enforced file type/size validation, malware scanning hooks, and metadata storage in DB. Joined officer/club data for 1099 records, ensured no raw SSN exposure, and added status tracking, bulk operations, and CSV export.",
        "testStrategy": "Tested W-9 uploads with allowed/disallowed files, verified malware scan flow, validated admin review completeness, confirmed SSN masking and correctness of CSV export and bulk actions.",
        "priority": "high",
        "dependencies": [
          2,
          3,
          4,
          5
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Implement Frontend Static HTML & Vanilla JS Pages",
        "description": "Responsive, accessible HTML pages implemented for all user flows using semantic markup and minimal vanilla JS.",
        "details": "Implemented public site pages (index, team, gallery, news, etc.), volunteer, officer, and admin pages. Admin dashboard includes dynamic interfaces. Semantic HTML with ARIA attributes, form validation and feedback, and mobile-responsive design without heavy frameworks.",
        "testStrategy": "Performed manual and automated accessibility tests (WCAG), responsiveness checks across devices, and form validation tests. Verified functional flows across roles.",
        "priority": "medium",
        "dependencies": [
          3,
          4,
          5,
          6,
          7
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Integrate Structured Logging and Audit Trails",
        "description": "Structured logging and audit trails implemented with correlation IDs, PII masking, and robust error handling.",
        "details": "Implemented logging via utils/logger.js for API requests, errors, and critical actions. Added correlation IDs and request tracking, ensured PII masking in logs, and stored logs securely. Added audit events for sensitive operations.",
        "testStrategy": "Triggered API requests and critical actions to verify correlation IDs, confirmed no PII leakage, and validated error logging and audit trail completeness.",
        "priority": "medium",
        "dependencies": [
          1,
          3,
          4,
          5,
          6,
          7
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Automate Backups and Migration Integrity Checks",
        "description": "Automated backups for database and blobs implemented with integrity verification and restore tooling.",
        "details": "Implemented nightly backups using Neon PostgreSQL and Vercel Blob APIs. Added integrity checks post-backup, restore scripts, and admin dashboard controls for backup/restore operations. Tested on staging prior to production usage.",
        "testStrategy": "Ran backup jobs, verified integrity checks, and performed restore tests on staging. Validated backup coverage and data consistency for both DB and files.",
        "priority": "high",
        "dependencies": [
          2,
          7
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Implement Health Check Endpoint and Error Messaging",
        "description": "Health check endpoint and standardized, non-sensitive error messaging are implemented and monitored.",
        "details": "Added GET /api/health for uptime monitoring, standardized error responses across the app, and integrated uptime/error rate monitoring support.",
        "testStrategy": "Tested health endpoint under normal and failure conditions and reviewed error messages for clarity and absence of sensitive details.",
        "priority": "medium",
        "dependencies": [
          1,
          3,
          4,
          5,
          6,
          7
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Documentation and Accessibility Compliance",
        "description": "Documentation is comprehensive and accessibility compliance maintained across the site.",
        "details": "Updated README.md, environment setup docs, backup/restore and logging documentation, and in-code API documentation. Conducted accessibility audits and remediated issues to maintain compliance.",
        "testStrategy": "Reviewed documentation for completeness and accuracy. Ran accessibility audit tools and manual checks to ensure WCAG compliance and reflected updates in docs.",
        "priority": "medium",
        "dependencies": [
          8,
          9,
          10,
          11
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Comprehensive Security Audit & Hardening for EWA Production",
        "description": "Perform a full-stack security audit and implement hardening across authentication, input/file handling, database queries, and PII protection for a production system handling SSNs and personal data.",
        "details": "Scope and objectives\n- Goal: Identify and remediate vulnerabilities across auth, input validation, file uploads, DB access, secrets, transport security, headers, logging, and PII/SSN handling in production and staging.\n- Standards and references: Align with OWASP Top 10 (A01–A10), NIST SP 800-53 controls relevant to web apps, and practical website audit checklists including SSL/TLS, input validation, session management, and security headers.[4][5]\n\nWork plan\n1) Discovery & asset inventory\n- Enumerate all public and internal endpoints, forms, file upload points, database connections, background jobs, third-party integrations, and storage locations for blobs/files and PII.\n- Map data flows for SSNs and personal data: collection points, processing, storage, logs, backups, exports.\n\n2) Authentication, authorization, and session security review\n- Review existing role-based auth from Task 3: session cookie flags (Secure, HttpOnly, SameSite=strict/lax), session rotation on login/privilege change, idle/absolute timeouts, and logout invalidation.\n- Enforce MFA for admin and privileged roles; add backup codes and rate limit login/MFA endpoints.[4]\n- Password policy: length, complexity, haveibeenpwned k‑anonymity checks, and server-side throttling with exponential backoff.[4]\n- Ensure HSTS with preload, TLS 1.2+, modern ciphers, and cert validity; redirect HTTP→HTTPS.[4]\n\n3) Input validation and output encoding\n- Centralize validation with a shared schema layer for all request bodies, query params, headers, and multipart fields; use allowlists for enums, lengths, and formats.\n- Implement context-appropriate output encoding (HTML, attribute, JS, URL) and a strict Content Security Policy (CSP) to mitigate XSS.[5]\n- Add global request size limits, nested object depth limits, and WAF-friendly error responses.\n\n4) File upload security\n- Enforce server-side MIME/type sniffing, magic-byte verification, max size, and extension allowlists.\n- Store uploads on blob storage with private ACLs; generate time-limited signed URLs for access.\n- Image handling: transcode to safe formats, strip metadata, and deny SVG unless sanitized.\n- Antivirus/antimalware scan on upload pipeline; quarantine and alert on detection.[5]\n\n5) Database query security and secrets\n- Mandate parameterized queries/ORM binds everywhere; prohibit string concatenation in queries; enable query linting in CI.\n- Implement row-level access checks in data access layer aligned to roles from Task 3.\n- Use least-privilege DB roles; rotate DB creds; enable TLS to DB; enforce statement timeouts; log slow/aborted queries without PII.\n\n6) PII/SSN protection and data minimization\n- Classify data fields by sensitivity. For SSNs: store only when necessary, encrypt at rest using application-layer encryption (envelope keys; KMS-managed master key), and tokenize where feasible.\n- Mask PII in UI, logs, and audit events; ensure redaction in errors and analytics.\n- Implement field-level access controls and purpose limitation checks for reads/exports.\n- Add data retention policies and secure deletion workflows; verify backups (Task 10) exclude unnecessary PII and are encrypted.\n\n7) Security headers and rate limiting\n- Enforce: CSP (default-src 'self'; no inline eval; specific allowlists), HSTS, X-Content-Type-Options, X-Frame-Options/SameSite defenses, Referrer-Policy, Permissions-Policy.[4][5]\n- Add per-endpoint rate limits and IP-based anomaly detection for auth, file upload, and data export routes.\n\n8) Monitoring, audit, and incident readiness\n- Extend structured logging and audit trails (Task 9) with security event taxonomy: auth failures, privilege changes, policy denials, upload rejects, AV detections, rate-limit hits.\n- Configure alerting thresholds and dashboards; define incident response runbooks with roles, containment steps, and regulatory notification templates.[5]\n\n9) Tooling and automation\n- Integrate SAST/secret scanning, dependency vulnerability scans, and DAST into CI; fail builds on criticals.[5]\n- Run periodic website security audit scans and configuration checks for SSL/TLS, headers, and exposures; document residual risks and exceptions.[1][2][3][4][5]\n\nDeliverables\n- Security Audit Report: findings categorized by severity, affected assets, evidence, exploitability, and remediation.\n- Hardening Changes: PRs with config/code changes, CSP/HSTS/headers, validators, query refactors, upload pipeline controls, encryption/tokenization.\n- Runbooks and Policies: incident response, key management, data retention, and PII handling SOPs.\n- Updated documentation touching auth, logging, and error messaging alignment with previous tasks.\n\nImplementation notes\n- Coordinate with DB schema (Task 2) for any new encrypted columns or token tables.\n- Leverage existing auth and logging foundations (Tasks 3 and 9) and ensure health/error messaging remain non-sensitive (Task 11).\n- Verify backups and restore paths accommodate encrypted PII and key management (Task 10).",
        "testStrategy": "Preparation\n- Set up staging mirroring production configs, with synthetic PII including SSNs. Ensure logging/audit trail capture is active without PII leakage.\n\nVerification steps\n1) Authentication & session\n- Check cookies: Secure, HttpOnly, SameSite; verify session rotation post-login and role elevation; test idle (e.g., 15–30 min) and absolute timeouts (e.g., 8–12 hours); confirm logout invalidation.\n- Attempt credential stuffing simulation with rate limiting in place; confirm throttle and no account enumeration in messages. Validate MFA enforcement for admin.\n\n2) Transport & headers\n- Scan TLS and HSTS settings; confirm HSTS preload eligibility and HTTP→HTTPS redirect. Validate presence and correctness of CSP, X-Content-Type-Options, X-Frame-Options/Frame-Ancestors, Referrer-Policy, Permissions-Policy headers.\n\n3) Input validation & XSS/CSRFi\n- Fuzz all endpoints with oversized payloads, nested JSON, invalid enums; confirm 4xx with sanitized error bodies. Use DAST to test reflected/stored XSS; verify CSP and encoding block payloads.\n- Verify CSRF protections on state-changing routes (tokens or same-site cookie strategy) and absence of dangerous CORS policies.\n\n4) File uploads\n- Upload polyglot files, oversized files, SVGs, and disguised executables; confirm rejection/quarantine and audit events. Verify content-type and magic-byte enforcement and that stored files are private and served via signed URLs.\n\n5) Database queries and access\n- Static search for string-concatenated SQL; ensure parameterization. Attempt forced browsing/IDOR to access other users’ records; confirm denials and audit logs. Validate DB role least-privilege and TLS to DB; test statement timeouts.\n\n6) PII/SSN protection\n- Inspect at-rest storage: ensure SSNs are encrypted or tokenized. Attempt to retrieve PII via logs, errors, analytics, and exports; confirm masking and access controls. Validate retention and secure deletion workflows. Confirm backups include encrypted data and keys are managed separately.\n\n7) Monitoring & incident response\n- Trigger representative security events (failed logins, rate-limit hits, AV detections) and confirm alerts, dashboards, and runbook execution steps. Verify audit trail completeness with correlation IDs and no PII leakage.\n\nEvidence & acceptance\n- Provide scan reports (SAST/DAST/deps), header/TLS scans, CSP violation reports, AV logs, and before/after config diffs. All critical/high findings remediated or risk-accepted with sign-off. Update docs/runbooks accordingly.",
        "status": "pending",
        "dependencies": [
          2,
          3,
          9,
          10,
          11
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Implement Performance Optimization & Monitoring for EWA",
        "description": "Optimize database queries, caching, frontend assets, and API response times, and implement end-to-end performance monitoring to improve user experience and reduce server load.",
        "details": "Scope and objectives:\n- Target p95 page load < 2.5s on 4G, p95 API latency < 300ms for common endpoints, and reduce DB CPU/IO by ≥25% under typical load.\n\n1) Baseline measurement and SLOs\n- Define service-level objectives (SLOs) for key user journeys (home, gallery/news pages, volunteer signup, officer/admin dashboard actions). Instrument Real User Monitoring (RUM) for Core Web Vitals (LCP, FID/INP, CLS) using PerformanceObserver in the frontend and send metrics to backend /api/metrics with correlation IDs from Task 9.\n- Add synthetic checks for critical pages and APIs using existing /api/health (Task 11) extended to include dependency timings (DB, cache, blob) and version/build info.\n\n2) Database query optimization (PostgreSQL)\n- Enable and review slow query logs (log_min_duration_statement) in staging/prod. Use EXPLAIN (ANALYZE, BUFFERS) to optimize hot paths: officer list/search, volunteer list/filter, 1099 lookups, admin dashboard aggregates (Tasks 4,5,6,7).\n- Add/adjust indexes (composite/partial) based on access patterns; ensure existing indexes from Task 2 align with query plans. Remove unused/duplicate indexes.\n- Refactor N+1 joins to batched queries; prefer SELECT specific columns over SELECT *; paginate with keyset pagination where applicable.\n- Add caching of infrequently changing reference data (e.g., club metadata) to reduce repeated reads.\n\n3) Caching strategy\n- CDN edge caching for static assets via Vercel/CloudFront: immutable asset filenames with content hashing; set Cache-Control: public, max-age=31536000, immutable. HTML: Cache-Control: no-store or short max-age with stale-while-revalidate for SSR pages if applicable.\n- API caching: implement server-side in-memory or Redis cache for read-heavy endpoints (e.g., public pages data, officer/club listings with filters that are cacheable). Use cache keys with versioning, per-role scoping to respect Task 3 auth constraints. Apply soft TTL + background revalidation. Honor PII masking from Task 9.\n- Database query result caching for expensive aggregates with explicit invalidation hooks on write paths in Tasks 4/5/6/7.\n\n4) Frontend performance improvements (Task 8 integration)\n- Asset optimizations: enable Brotli/Gzip compression; tree-shake and minify JS/CSS; split vendor vs app bundles; defer/non-blocking scripts; preload critical CSS; inline minimal critical CSS for above-the-fold; lazy-load non-critical images/components; use responsive images (srcset, sizes) and modern formats (WebP/AVIF) with fallbacks.\n- Reduce third-party scripts; audit for unused code; set priority hints (fetchpriority) for hero media; use native lazy loading (loading=lazy) for images/iframes where safe.\n\n5) API response time optimization\n- Standardize pagination and projection (select only needed fields) for list endpoints; enforce limits and sensible defaults.\n- Add request-level timeouts and circuit breakers for external calls (e.g., malware scan hooks in Task 7) and perform async/offline processing where feasible.\n- Implement streaming or chunked responses for large CSV exports while maintaining audit logging (Task 9).\n\n6) Monitoring & alerting\n- Server-side metrics: integrate OpenTelemetry (OTel) for traces, spans, and metrics across API, DB, cache, blob storage. Propagate correlation IDs from Task 9. Export to a managed backend (e.g., Grafana Cloud/OTel collector). Track latency histograms, error rates, throughput, cache hit ratio, DB wait events.\n- Frontend RUM: capture CWV and navigation timing, JS error rates, and SPA route timings. Sample at configurable rates; anonymize and avoid PII per Task 9.\n- Dashboards: create dashboards for CWV, API p50/p95/p99 latencies by endpoint, error rates, DB slow queries, cache hit/miss, and resource usage. Alerts on SLO breaches with burn-rate policies.\n\n7) Documentation and operations\n- Document caching keys, TTLs, and invalidation rules; playbooks for common performance incidents; SLOs and alert thresholds. Include rollback toggles/feature flags for each optimization.\n\nImplementation notes\n- Ensure all caching respects role-based access and PII masking from Tasks 3 and 9. Do not cache user-specific sensitive responses at shared layers. Add Vary headers for Authorization or use per-user cache scopes as needed.\n- Add automated performance budget checks in CI (e.g., Lighthouse CI for key pages; k6 load tests for APIs) with thresholds aligned to SLOs.\n",
        "testStrategy": "Baseline and regression\n- Capture baseline: run Lighthouse (mobile, 4x CPU slow, 4G) on index, news/gallery, volunteer signup, admin dashboard; record CWV. Run k6 load tests for top 5 APIs (list officers, list volunteers, 1099 list, admin dashboard summary, public content) at 50–200 VU with realistic think times; record p50/p95/p99 and error rate.\n\nDB optimization validation\n- Enable slow query log and run representative workflows; list queries >200ms. After optimizations, re-run and verify ≥50% reduction in count of slow queries and ≥25% lower mean execution time for targeted queries. Validate query plans changed as expected (index usage, fewer rows).\n\nCaching tests\n- Unit/integration tests for cache layers: verify cache key correctness, TTL expiry, invalidation on POST/PUT/DELETE of related resources, and no leakage across roles. Measure cache hit ratio ≥70% for designated endpoints under load test replay.\n\nFrontend performance\n- Lighthouse CI gates: LCP ≤2.5s, CLS ≤0.1, INP ≤200ms on mobile emulation. Verify image formats/responsive attributes in markup, script defer/async usage, and bundle size reductions vs baseline.\n\nAPI latency\n- Re-run k6 after changes: confirm p95 latency <300ms for targeted read endpoints at test load; verify rate limiting/back-pressure doesn’t degrade UX. Validate CSV export uses streaming and maintains audit logs.\n\nMonitoring & alerting\n- Validate OTel traces include correlation IDs and span DB/cache calls. Trigger synthetic errors/latency to test alerting and burn-rate policies. Verify dashboards show CWV, API latencies, DB slow queries, and cache metrics with correct labels.\n\nSecurity & privacy\n- Confirm no PII is stored in metrics/logs; check headers and caches for role-based scoping; validate Vary/Cache-Control headers. Perform authorization checks on cached responses.\n",
        "status": "pending",
        "dependencies": [
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Enhance UX/UI, Accessibility, and Progressive Enhancement across EWA (Admin + All Roles)",
        "description": "Improve admin dashboard usability, strengthen form validation and user feedback, add progressive enhancement for mobile, implement keyboard navigation, and elevate accessibility and UI consistency for all user roles.",
        "details": "Scope and goals\n- Elevate usability and accessibility of the EWA website with a focus on the admin dashboard and shared components across roles (admin, booster, officer, volunteer, public).\n- Deliver WCAG 2.2 AA compliance, robust client-side and server-side validation with actionable feedback, full keyboard operability, and progressive enhancement that preserves core features without JS.\n\nImplementation plan\n1) Admin dashboard UX improvements\n- Information architecture: reorganize dashboard to prioritize critical KPIs and primary actions using card-based layout, clear hierarchy, and progressive disclosure to reduce clutter.\n- Navigation: ensure consistent sidebar/topbar with clear labels, icons, and keyboard-focusable collapsible sections; add skip links to dashboard content area.\n- Data tables: add column sorting, filtering, pagination; preserve state in URL params; responsive tables with overflow strategies; provide empty/loading states.\n- Customization (lightweight): allow user preference for density (comfortable/compact) and persisted column visibility per table.\n\n2) Forms: validation, feedback, and resilience\n- Client-side validation using Constraint Validation API plus custom validators; server-side validation remains source of truth.\n- Inline, accessible error messages bound via aria-describedby; summary alert at top with links to invalid fields.\n- Distinguish statuses with iconography and color plus text; prevent color-only communication.\n- Async submission with optimistic UI where safe; disable double submit; preserve user input on validation errors; add success toasts/snackbars with undo where applicable.\n\n3) Progressive enhancement and mobile experience\n- Ensure all critical flows work with JS disabled (basic form POST fallbacks, server-rendered responses, pagination links).\n- Enhance with JS for filters, live validation, and dynamic tables; load enhancements conditionally and defer non-critical scripts.\n- Improve touch targets (≥44x44px), responsive spacing/typography, and orientation handling; test on low-end/mid-tier devices and 4G.\n\n4) Keyboard navigation and focus management\n- Define global focus order and visible focus styles; add skip-to-content and skip-to-navigation links.\n- Manage focus after route/content updates (focus main heading); trap focus in modals/drawers; ESC to close; ensure menus, tabs, accordions, and comboboxes meet ARIA Authoring Practices.\n- Provide keyboard shortcuts for frequent admin actions (discoverable via help modal, e.g., ? to open palette, / to focus search).\n\n5) Accessibility upgrades (WCAG 2.2 AA)\n- Headings and landmarks: unique h1 per page, main/nav/aside/footer landmarks; label search, filters, and tables.\n- Color contrast: meet 4.5:1 for text; audit and update palette/tokens; ensure focus indicator contrast.\n- Errors, status, and live regions: use role=alert/aria-live for async results; associate labels with inputs; larger hit areas; prevent motion sensitivity with reduced motion.\n- Tables and charts: add table headers, scope, captions; for charts, provide data tables or text summaries.\n\n6) UI consistency and design tokens\n- Establish or update design tokens (color, spacing, typography, radius, elevation, focus ring) and component guidelines; document patterns for cards, tables, forms, alerts, modals.\n- Apply tokens across pages for consistent look-and-feel.\n\n7) Non-functional\n- Maintain security headers and sanitized error messages; no leakage of sensitive data in UI.\n- Ensure changes do not degrade performance; coordinate with performance task by deferring enhancements and tree-shaking.\n\nDeliverables\n- Updated admin dashboard layout and components (cards, tables, filters, navigation).\n- Shared form components with validation and feedback.\n- Accessibility-compliant components and patterns with documentation.\n- Keyboard navigation, shortcuts, and focus management utilities.\n- Progressive enhancement utilities and JS-disabled fallbacks.\n- Changelog and upgrade notes for developers.\n",
        "testStrategy": "Accessibility and usability\n- Automated: run axe-core and eslint-plugin-jsx-a11y (or equivalent) on key pages; target zero critical violations.\n- Manual WCAG checks: keyboard-only traversal of all flows; verify visible focus, skip links, modals focus trap, correct ARIA roles, landmarks, headings, and error associations.\n- Screen reader passes: NVDA + Firefox, VoiceOver + Safari; validate form error announcements, live updates, table headers, and navigation.\n\nForms and validation\n- Turn off JS and submit invalid/valid forms; verify server-side errors display and inputs persist.\n- With JS on, test inline validation, summary alerts, and prevention of double-submit; simulate slow network and retry flows.\n\nAdmin dashboard functionality\n- Verify table sorting/filtering/pagination work and state persists via URL; test empty/loading/error states.\n- Resize tests from 320px to desktop; confirm responsive tables and touch target sizes; orientation change handling.\n- Preference persistence for density/columns via localStorage or user profile as designed.\n\nProgressive enhancement\n- Disable JS globally and validate critical journeys: login, list pages, create/edit forms, 1099 views; ensure baseline is usable.\n- Throttle network to 4G; confirm enhanced features load after content; no blocking of first interaction.\n\nKeyboard shortcuts and focus\n- Verify shortcuts are discoverable and can be disabled; ensure no conflicts with screen readers; test ESC to close modals, / to focus search, ? to open help.\n\nRegression and non-functional\n- Cross-role verification: admin, booster/officer, volunteer, public pages.\n- Check standardized, non-sensitive error messages still apply; confirm health endpoint unaffected.\n- Spot-check performance budgets (no >10% increase in JS payload vs baseline) and coordinate with performance monitoring.\n",
        "status": "pending",
        "dependencies": [
          3,
          8,
          11,
          12
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Implement Advanced Reporting, Analytics Dashboards, and Data Export",
        "description": "Build role-based analytics dashboards with visualizations for volunteers, 1099 forms, and officer management, including filtering, sorting, search, and export capabilities to enable data-driven decisions.",
        "details": "Scope and objectives:\n- Deliver role-specific dashboards for Admin and Booster roles with KPIs, charts, and tabular reports.\n- Provide volunteer statistics, 1099/W-9 analytics, and officer management reports with rich filtering, sorting, search, and export (CSV/XLSX, print-to-PDF) while honoring RBAC and PII masking.\n\nKey features:\n1) Role-based dashboards\n- Admin dashboard: global KPIs (total volunteers, active this season, hours contributed, clubs covered), 1099 pipeline (submitted, in-review, approved, exceptions), officer coverage by club, at-risk compliance indicators, recent audit events.\n- Booster/Officer dashboard: club-scoped KPIs, volunteer funnel, pending W-9/1099 items for their club, officer roster health, upcoming deadlines.\n- Respect role-based data visibility and row-level scoping using existing auth context and role checks.\n\n2) Data visualizations\n- Charts: time-series (signups per week), categorical (volunteers by interest, availability bands), stacked bars (1099 status by club), donut (officer roles mix), heatmap/calendar (volunteer activity by day if available).\n- Implement with a lightweight chart lib (e.g., Chart.js or ECharts) with accessible color palettes and high-contrast mode.\n- All charts must have descriptive labels, aria-describedby, and data table toggle for screen readers.\n\n3) Reports\n- Volunteers: filters (date range, club, interest, availability, status), multi-column sort, full-text search on name/email but display only masked PII per policy.\n- 1099/W-9: filters (status, date range, officer, club), error/exception buckets, export of admin-safe fields; never export SSN or sensitive document links.\n- Officer management: filters (club, role, term expiration), flags for vacancies, duplicates, and expiring terms.\n\n4) Exports and printing\n- Server-side CSV and XLSX export endpoints for each report; paginate on client, stream on server for large results.\n- Print-friendly views and PDF print via browser with dedicated CSS; include report title, filters applied, timestamp, and footer with page numbers.\n- Apply RBAC and row-level constraints to exports; add audit trail events for each export request.\n\n5) Performance and UX\n- Backend query optimization with indexed filters; stable, deterministic sorting; cursor-based pagination for large datasets.\n- Client-side debounced search, persisted filter state in URL query params, and saved views per user role.\n- Empty/loading/error states; no blocking spinners longer than 300ms without skeletons.\n\n6) Security, privacy, and auditability\n- Enforce role checks on all dashboard and export endpoints; ensure PII masking consistent with existing policies.\n- Log audit events for report views and exports with correlation IDs.\n- Redact sensitive fields in responses and logs; validate and sanitize all filter inputs.\n\nImplementation plan:\n- Backend\n  - Add reporting endpoints: GET /api/reports/volunteers, /officers, /1099/summary, /1099/detail, with filters: ?clubId=&role=&status=&from=&to=&q=&sort=&order=&cursor=&limit.\n  - Implement aggregation endpoints for KPIs and chart series: GET /api/analytics/kpis, /timeseries, /breakdowns; scope results by role.\n  - Add export endpoints: GET /api/exports/{report}.csv and .xlsx, streaming with text/csv or application/vnd.openxmlformats-officedocument.spreadsheetml.sheet; include Content-Disposition with filename containing timestamp and filters hash.\n  - Reuse existing schemas (users, volunteers, officers, form_1099) and indexes; add read-only views or materialized views for common aggregations if needed.\n  - Integrate audit logging on every analytics/extract request via existing logger utilities.\n- Frontend\n  - Create /dashboard routes for Admin and Booster with role guard.\n  - Build filter bars (date picker, multiselects for club/role/status), search box, and table with column toggles.\n  - Add charts with accessible legends and data table toggle; implement responsive grid layout.\n  - Implement saved filters (localStorage) and sharable links (URL params).\n  - Add Export buttons with progress feedback and confirmation about PII policy.\n\nAccessibility and compliance:\n- WCAG AA contrast, keyboard navigable filter controls, table headers with scope, aria-live for loading state.\n- Mask emails/phone where policy requires; show tooltips explaining masking to users.\n\nOperational considerations:\n- Document API contracts and filter semantics.\n- Add rate limiting to export endpoints; cap row counts with admin override.\n- Feature flags to progressively roll out dashboards per role.\n",
        "testStrategy": "API and backend tests:\n- Unit tests for filter parsing, RBAC scoping, and query builders for each endpoint.\n- Integration tests validating row-level restrictions: admin sees cross-club aggregates; booster sees only their club.\n- Verify PII masking in list and export responses; confirm SSN and document links never appear.\n- Load tests for aggregation and export endpoints at realistic volumes; confirm p95 latency targets and stream correctness.\n- Audit trail assertions: exports and report views produce entries with correlation IDs.\n\nFrontend tests:\n- Component tests for filter bar, tables (sorting, pagination), and charts (render with sample data, accessible labels present).\n- E2E flows per role: login -> dashboard renders correct KPIs and restricted data; apply filters, search, and multi-column sort; export CSV/XLSX and verify downloaded file headers and applied filters metadata.\n- Accessibility tests: keyboard-only navigation through filters and tables; axe checks for color contrast and ARIA attributes; screen reader verification of chart data table toggle.\n- Print view tests: ensure headers/footers, page breaks, and applied filters appear; PDF generated via browser contains correct content.\n\nSecurity and privacy tests:\n- Attempt to access admin-only endpoints as booster; expect 403.\n- Tamper with URL query params for clubId to escalate scope; expect server to enforce row-level limits.\n- Validate rate limiting on export endpoints and logging redaction.\n",
        "status": "pending",
        "dependencies": [
          2,
          3,
          4,
          6,
          7,
          8,
          9,
          10
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "Implement Automated Testing, Security Scans, and CI/CD for EWA",
        "description": "Build a comprehensive automated QA suite (unit, integration, end-to-end) for EWA APIs, DB operations, and user workflows; add automated security testing; and implement a CI/CD pipeline to run tests and deploy safely to staging/production.",
        "details": "Scope and goals:\n- Establish a unified testing framework covering: unit tests for API handlers and utilities; integration tests exercising DB operations and migrations; end-to-end (E2E) browser tests for key user journeys; automated security testing (dependency and application-level); and gate all via CI/CD with test artifacts, flaky-test mitigation, and code quality checks. Focus on maintainability and preventing regressions through repeatable pipelines and clear reporting.[3][4]\n\nTest architecture and tooling:\n- Unit/API: Use Jest/Vitest with supertest to hit API routes in-memory or via test server. Mock external services (e.g., Vercel Blob, email) and use test doubles for logger to assert PII masking.\n- Integration (DB): Spin up ephemeral PostgreSQL (Docker or Testcontainers). Apply migrations, seed minimal fixtures (admin, officer, volunteer, 1099 sample) to validate referential integrity and triggers from Task 2.\n- E2E: Use Playwright for cross-browser (Chromium/WebKit/Firefox) E2E covering login, role-based access (admin, booster), volunteer signup, 1099 flows, admin dashboard, file upload constraints, and CSV export. Run headed locally, headless in CI with video, screenshots, and tracing.[4]\n- Security automation: \n  - SCA/Dependency: Enable npm/yarn audit, OWASP Dependency-Check or Snyk step failing on high/critical.\n  - SAST: Add ESLint security plugins and Semgrep rules tuned for Node/JS.\n  - DAST: Run OWASP ZAP baseline scan against staging preview; exclude authenticated-only routes unless auth context is configured.\n- Code quality gates: Enforce coverage thresholds (e.g., 80% lines/branches on unit/integration), lint/type checks, formatting, and disallow TODO/FIXME in changed lines.\n\nTest implementation plan:[1][3]\n1) Identify candidates for automation prioritizing high-frequency, regression-prone paths: auth, protected APIs, volunteers CRUD, 1099 upload/review/export, admin dashboards, health checks, and backup controls.[4]\n2) Define test cases precisely with steps and expected outcomes; store as living specs alongside tests.[2][3]\n3) Implement framework structure:\n   - packages/tests or tests/ with folders: unit/, integration/, e2e/, security/.\n   - Shared helpers: auth/login helpers, test data builders, DB reset utilities, and file fixtures for allowed/disallowed uploads.\n   - Environment handling: .env.test with isolated secrets; CI secrets via environment variables.\n4) Data strategy:\n   - Use factories to generate users with roles (admin, booster) and volunteers; seed 1099 records. Provide teardown/reset between tests. For E2E, seed via API or direct DB in a known schema snapshot.\n5) Flake control:\n   - Use Playwright auto-waiting, network idle assertions, and retry-on-failure for known flaky specs. Quarantine flaky tests with labels and track in CI reports.\n6) Reporting:\n   - JUnit XML for CI annotations, HTML reports for E2E with videos and traces, coverage reports uploaded as artifacts. Trend dashboards in CI summaries.[3]\n\nCI/CD pipeline:\n- Triggers: PRs, pushes to main, nightly scheduled.\n- Jobs (in order):\n  1) Setup: node install, cache deps; lint + typecheck.\n  2) Unit/API tests with coverage; upload artifacts.\n  3) Integration tests using Postgres service/Testcontainers; run migrations; upload coverage.\n  4) Build app.\n  5) E2E on ephemeral preview (spin app on random port) or deploy-to-preview then run Playwright against preview URL; capture screenshots/videos/traces.\n  6) Security: npm audit/Snyk, Semgrep, ZAP baseline; fail on high/critical or configurable policy.\n  7) Aggregate coverage; enforce thresholds; post PR annotations.\n  8) Deploy: On protected main after all checks pass, deploy to staging; gated manual approval to promote to production. Post-deploy smoke tests (health, key endpoints) and rollback on failure.\n\nKey test coverage mapped to prior tasks:\n- Task 3 (AuthN/Z): unit tests for session middleware; E2E for login/logout, role route guards, privilege escalation attempts.\n- Task 4/6 (CRUD + Volunteers): integration tests for referential integrity, validation; E2E flows for create/edit/list with role checks.\n- Task 7 (1099/W-9): file upload validation (type/size), malware-scan hook mock, SSN masking, admin review, bulk actions, CSV export correctness.\n- Task 8 (Frontend): accessibility smoke via axe-core in Playwright; form validations and ARIA roles.\n- Task 9 (Logging/Audit): assert no PII in logs using logger mock; audit events emitted on sensitive operations.\n- Task 10 (Backups): admin backup/restore controls visibility and basic happy-path trigger in staging-only context.\n- Task 11 (Health): uptime endpoint assertions and standardized error payload checks.\n\nOperational considerations:\n- Separate test and prod resources; do not run destructive tests against prod. Use feature flags where necessary.\n- Parallelize tests by shard; ensure DB isolation per worker (schema suffixing) to avoid contention.\n- Document how to run all test suites locally with make/npm scripts and how failures block merges in CI.\n\nDeliverables:\n- Test suites with >80% unit/integration coverage on critical modules, stable E2E pack for smoke and regression, security scans integrated, and a CI/CD pipeline with clear pass/fail gates and artifacts.[2][3][4]",
        "testStrategy": "Verification checklist:\n- Unit/API tests:\n  - Run npm test:unit with coverage ≥80% lines/branches on auth middleware, validators, controllers for CRUD, volunteers, and 1099 endpoints.\n  - Validate that sensitive fields are masked in responses and logs via tests.\n- Integration (DB):\n  - Execute npm test:integration using ephemeral Postgres; migrations apply cleanly; foreign keys/triggers enforced; create/update/delete flows succeed and invalid inputs fail with standardized errors.\n  - Concurrency test: parallel create/update does not violate constraints; transaction rollbacks work.\n- E2E (Playwright):\n  - Smoke suite runs in <10 min across Chromium/WebKit/Firefox in CI and passes consistently 3 consecutive runs.\n  - Scenarios: login/logout; role access denied for non-privileged users; volunteer signup flow; admin dashboard data loads; W-9 upload rejects invalid types, accepts valid sample, admin review + status change persist; CSV export downloads and schema validated; health endpoint green; basic accessibility violations < threshold using axe.\n  - Artifacts: videos, screenshots, and traces uploaded for failures.\n- Security automation:\n  - SCA/SAST steps execute and report; pipeline fails on high/critical vulnerabilities; Semgrep ruleset covers common Node/Express issues.\n  - ZAP baseline runs against preview/staging URL, produces report artifact; no medium/high alerts remain unresolved or are risk-accepted with documented justifications.\n- CI/CD gates:\n  - On PR: lint/typecheck, unit, integration, E2E, security all required to merge; coverage gate enforced; PR annotations visible for failing tests and lines.\n  - On main: staging deploy occurs only after all checks pass; post-deploy smoke tests pass; manual approval required before production; rollback tested by forcing a failing smoke test.\n- Flake control: test retries <=2; flaky rate <2% over 10 nightly runs; quarantine list tracked.\n- Documentation: README/QA guide includes setup, commands, and how to triage failures; developers can run full suite locally successfully.\n- Evidence: attach CI run links, coverage summary, ZAP/Semgrep reports, and sample artifacts to the task for review.",
        "status": "pending",
        "dependencies": [
          2,
          3,
          4,
          6,
          7,
          8,
          9,
          10,
          11
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 18,
        "title": "Implement Disaster Recovery and Business Continuity (DR/BC) for EWA",
        "description": "Design and implement end-to-end disaster recovery and business continuity capabilities, including automated backup verification, point-in-time recovery (PITR), health monitoring and alerting, runbooks, and failover procedures to keep the EWA site operational during outages.",
        "details": "Scope and objectives:\n- Recovery Time Objective (RTO): ≤ 30 minutes for critical APIs and authentication; Recovery Point Objective (RPO): ≤ 15 minutes for database and blobs.\n- Maintain core operations (public pages, auth, volunteer/1099 admin) during partial outages via documented procedures and automation.\n\n1) DR architecture and capabilities\n- Database (PostgreSQL/Neon):\n  - Enable/verify continuous backups and PITR; document retention policy (e.g., 14–30 days) and PITR restore procedure using a timestamp/LSN.\n  - Create automated PITR restore script to a staging/DR instance (read-only) with parameterized timestamp and safety checks to avoid restoring over production.\n  - Implement logical dump snapshots daily as a secondary layer (pg_dump with schema+data) to complement provider PITR.\n- Blob storage (Vercel Blob):\n  - Verify object versioning/immutability if available; otherwise implement periodic manifest snapshots and cross-region replication if supported.\n  - Build verification job to sample-validate checksums/hashes of blob objects against stored metadata from Task 10; reconcile missing/corrupt items.\n- Application/config:\n  - Externalize configuration for DR (feature flags, env groups). Store encrypted .env.example.dr and document required secrets rotation.\n  - Create infra-as-code or scripts to stand up a warm-standby environment (staging as DR) with minimal changes (DNS/edge routing toggle, env promotion).\n\n2) Automated backup verification and drills\n- Extend Task 10 backup jobs to include:\n  - Post-backup validation: run pg_restore --list and integrity queries on a disposable instance; compute row counts per key tables and compare against production snapshot deltas.\n  - Blob verification: sample N% of objects nightly and 100% weekly by key collections (1099 docs, W-9 uploads) using size/hash comparison.\n- Scheduled DR drill pipeline (monthly):\n  - Execute PITR restore to a DR instance at a chosen timestamp; run smoke test suite; produce drill report with RTO/RPO achieved and discrepancies.\n\n3) Monitoring, alerting, and health signals\n- Build unified monitoring based on Task 11 health endpoint and Task 9 logs:\n  - Uptime/latency SLOs: alert when p95 API latency > 300ms sustained 15 min or error rate > 2%.\n  - Backup job status, verification failures, PITR drill failures, storage quota thresholds, DB replica lag.\n  - Implement alert routing (email/Slack/PagerDuty) with severity levels; include runbook links in alert payloads.\n\n4) Runbooks and incident response\n- Create concise, role-targeted runbooks in /docs/runbooks for:\n  - DB point-in-time restore to DR; promoting DR to primary; rolling back promotion.\n  - Blob/data recovery for missing/corrupt objects.\n  - Partial outage: degraded DB, blob unavailability, auth/session issues, upstream provider incident.\n  - Security incident containment steps relevant to data restores (coordinate with audit trails from Task 9).\n- Include decision trees, commands, required permissions, and estimated timelines. Maintain a DR checklist and a communications template.\n\n5) Quick recovery procedures and automation\n- One-command DR activation scripts:\n  - dr/restore_db.sh: perform PITR to new instance; outputs connection URL.\n  - dr/swap_env.ts: switch app environment variables to DR endpoints; flush caches; warm critical pages/APIs.\n  - dr/dns_failover.md: steps for traffic switch (manual with safeguards). Where possible, add provider API automation for DNS/edge routing.\n- Data reconciliation:\n  - After failback, run diff scripts to compare DR and primary data ranges and apply forward migrations for write gaps within RPO tolerance.\n\n6) Documentation and training\n- DR/BC plan covering objectives, roles, inventories (systems, dependencies, secrets), and contact matrix.\n- Schedule quarterly tabletop exercises; capture lessons learned; update RTO/RPO and runbooks accordingly.\n\nSecurity and compliance considerations:\n- Ensure PII masking in logs per Task 9 during DR drills.\n- Encrypt backups at rest and in transit; restrict access with least privilege and audit access events.\n- Avoid restoring sensitive data into shared environments without access controls.\n",
        "testStrategy": "Verification plan\n1) Backup and verification\n- Trigger nightly backup job and confirm success logs with integrity checks for DB and blobs. Intentionally corrupt a sampled blob and verify alert and auto-reconciliation report.\n- Run pg_restore on a disposable instance and validate row counts vs. production snapshot (±RPO window).\n\n2) PITR capabilities\n- Choose a timestamp T; create a test transaction after T; perform PITR to T and verify the post-T transaction is absent while pre-T data exists.\n- Execute automated PITR drill and capture RTO/RPO metrics; assert RTO ≤ 30 min and RPO ≤ 15 min.\n\n3) Monitoring and alerting\n- Simulate failures: force a backup job to exit non-zero, inject health endpoint errors to push error rate > 2%, and simulate DB replica lag. Confirm alerts fire with correct severity and include runbook links.\n- Validate p95 latency alerts by adding artificial delay in a canary endpoint and confirming alert thresholds and recovery notifications.\n\n4) Runbooks\n- Follow each runbook end-to-end on staging: perform DR promotion and rollback; measure time taken and steps count; ensure no hardcoded secrets, and commands succeed as documented.\n- Peer review runbooks; run a tabletop exercise and record action items.\n\n5) Quick recovery automation\n- Execute dr/restore_db.sh and dr/swap_env.ts in staging; confirm app reads from DR DB and serves core flows (public pages, auth, volunteers, 1099 admin) with acceptable latency.\n- Perform failback to primary; run reconciliation scripts and verify data parity within RPO tolerance.\n\n6) Security and compliance\n- Verify backups are encrypted, access is audited, and no PII appears in drill logs. Attempt unauthorized access to backup artifacts and confirm denial and alerting.\n",
        "status": "pending",
        "dependencies": [
          2,
          7,
          9,
          10,
          11
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 19,
        "title": "Implement Code Coverage Analysis, Reporting, and Dashboard Integration",
        "description": "Set up Jest-based unit testing and code coverage collection, create comprehensive test suites for API endpoints and DB functions, enforce coverage thresholds, and surface coverage metrics in the admin dashboard.",
        "details": "Scope and objectives:\n- Establish a consistent Jest test framework for backend/server code and any shared utilities.\n- Collect and enforce code coverage with actionable reports (HTML, lcov, text-summary) and coverage thresholds to prevent regressions.\n- Author unit tests for all API endpoints (volunteers, booster CRUD, 1099/W-9, auth) and database functions/queries.\n- Integrate coverage results into the admin dashboard to provide visibility into code quality metrics for admins.\n\nImplementation plan:\n1) Jest setup and configuration\n- Add dev dependencies: jest, ts-jest or babel-jest (match project toolchain), @types/jest (if TS), supertest for HTTP testing, and cross-env.\n- Create jest.config.(js|ts) with:\n  - testEnvironment: \"node\"\n  - clearMocks: true\n  - collectCoverage: true\n  - coverageDirectory: \"coverage\"\n  - coverageReporters: [\"text\", \"text-summary\", \"lcov\", \"html\"]\n  - collectCoverageFrom: [\n    \"src/**/*.{js,ts}\",\n    \"!src/**/__tests__/**\",\n    \"!src/**/migrations/**\",\n    \"!src/**/scripts/**\"\n  ]\n  - coveragePathIgnorePatterns for node_modules, generated types, and config files.\n  - testMatch to include **/*.test.(js|ts) and **/*.spec.(js|ts).\n  - coverageThreshold.global: { branches: 80, functions: 85, lines: 85, statements: 85 } with a path-specific override for generated code if needed. [Use CLI: --coverage and --collectCoverageFrom in CI as a fallback.]\n\n2) Test utilities\n- Create a lightweight test server bootstrap (e.g., app factory) to mount API routes without starting network listeners.\n- Add DB test harness: transaction sandboxing or per-test schema reset; use a dedicated test database and seed minimal fixtures.\n- Provide auth helpers to mint valid/invalid sessions/tokens for role-based tests (admin, officer, booster), leveraging Task 3’s implementation.\n\n3) Unit and integration tests for APIs\n- Booster Club CRUD (Task 4): tests for create/read/update/delete, validation errors, referential integrity, and role restrictions (admin vs. officer). Include CSV import happy-path and failure cases.\n- Volunteer APIs (Task 6): tests for minimal PII constraints, field validation, and access control per role.\n- 1099/W-9 workflow (Task 7): tests for GET/POST endpoints, file type/size validation stubs, malware-scan hook behavior (mock), metadata persistence, SSN masking, admin review flows, bulk actions, and CSV export.\n- AuthN/Z (Task 3): tests for protected routes, session expiration, and denial of privilege escalation attempts.\n- Public endpoints/pages (Task 8 APIs if any) basic reachability and caching headers if applicable.\n- Error handling and logging hooks (Task 9): verify that errors are captured and PII is masked by asserting logger calls with redacted fields (mock logger).\n\n4) Database function and query tests (Task 2)\n- Unit-test query builders/repositories with seeded fixtures; assert indexes/constraints behavior via expected errors on violations.\n- Verify triggers/UUIDs and default seeds where applicable.\n\n5) CI integration\n- Add npm scripts:\n  - \"test\": \"jest\"\n  - \"test:coverage\": \"jest --coverage\"\n  - \"test:watch\": \"jest --watch\"\n- In CI, run test:coverage and upload coverage artifacts. Optionally integrate Codecov or GitHub Actions coverage summary comment using lcov.\n\n6) Admin dashboard integration\n- Backend: add an endpoint /api/metrics/coverage that reads the latest coverage/coverage-summary.json and returns aggregates (lines, branches, functions, statements: total/covered/pct) and per-package/module summaries. Cache for short TTL (e.g., 60s) and guard with admin role.\n- Frontend (admin dashboard): add a Code Quality widget showing:\n  - Overall coverage percentages with status coloring vs thresholds\n  - Trend sparkline from last N CI runs if CI exposes history (store last N summaries in DB or file store), else show latest only\n  - Drill-down link to open the HTML report in a protected route (serve from static artifact path or proxy read of coverage HTML index).\n\n7) Developer workflow\n- Document how to run tests locally with coverage, interpret reports, and add tests for new endpoints. Include guidance on when to adjust thresholds and how to exclude generated code safely.\n\nSecurity and privacy considerations:\n- Do not log raw PII in tests; use synthetic data and assert redaction.\n- Limit exposure of coverage HTML to admin-only routes. Avoid leaking source paths in public.\n\nDeliverables:\n- jest.config.* committed with thresholds and reporters.\n- Comprehensive test suites for listed APIs and DB functions.\n- CI job running coverage and storing artifacts.\n- Admin dashboard widget + backend API for coverage summary and optional HTML report access.\n- README updates for testing workflow.\n",
        "testStrategy": "Unit and integration verification:\n1) Configuration and thresholds\n- Run `npm run test:coverage` locally; confirm coverageSummary is generated (coverage/coverage-summary.json) and HTML report exists.\n- Lower a test count to force thresholds to fail; verify Jest exits non-zero and CI job fails.\n\n2) API endpoint tests\n- Booster CRUD: create/update/delete happy paths, invalid payloads, foreign key violations, and role restrictions (officer denied where appropriate, admin allowed). Assert correct HTTP status codes and response shapes.\n- Volunteers: validate minimal PII storage and access control. Attempt unauthorized access and expect 401/403.\n- 1099/W-9: upload allowed and disallowed files (mock storage and malware scanner), verify SSN masking in responses, test admin review actions, bulk ops, and CSV export content and MIME type.\n- Auth protected routes: attempt privilege escalation; expect denial and audit logging call.\n\n3) Database tests\n- Seed fixtures, run repository/functions; assert expected rows, constraints, trigger effects (UUIDs, timestamps). Attempt violating inserts to confirm errors.\n\n4) Logging and redaction\n- Mock logger and assert no PII; verify correlation IDs present in logged entries for API calls.\n\n5) Admin dashboard integration\n- With a generated coverage report present, call /api/metrics/coverage as admin: expect 200 with correct aggregates and per-file/module entries; as non-admin: expect 403.\n- Render widget: verify percentages, threshold coloring, and that the HTML report link opens to the protected report route. Remove coverage files and expect dashboard to show a clear “no report available” state without errors.\n\n6) CI\n- Confirm CI uploads lcov artifact and surfaces summary in job output. Break a test to ensure CI fails and dashboard does not update until fixed.\n",
        "status": "done",
        "dependencies": [
          2,
          3,
          4,
          6,
          7,
          8,
          9
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 20,
        "title": "Implement Security Vulnerability Scanning, Automation, and Admin Dashboard Reporting",
        "description": "Add end-to-end security scanning for dependencies and custom code using npm audit and a secondary scanner (Snyk/OWASP ZAP), automated CI checks with policy gates, and an admin dashboard module to surface vulnerabilities, aging, dependency updates, and recommendations.",
        "details": "Scope\n- Dependency scanning: integrate npm audit with CI, parse JSON output, enforce fail thresholds, and implement automated remediation workflows.\n- Secondary scanning: integrate either Snyk (SCA/SAST) or OWASP ZAP (DAST for staging) for breadth across dependencies, code, and runtime.\n- Admin dashboard: new Security section to visualize current/ historical vulnerabilities, dependency update backlog, and prioritized recommendations.\n- Tracking: persist normalized findings with status (open, in-progress, resolved), severity, package, version, path, CVE, first_seen, last_seen, SLA due.\n\nImplementation Plan\n1) CLI/Local tooling\n- Add npm scripts: \"scan:deps\": \"npm audit --json\", \"scan:deps:fix\": \"npm audit fix\", \"scan:deps:fix:force\": \"npm audit fix --force\".[3][4]\n- Document usage and audit levels (e.g., --audit-level=high to fail on high+ in CI).[3]\n\n2) CI integration\n- Create a reusable CI job (GitHub Actions/your CI) that runs on PRs and nightly:\n  - Setup Node, install with clean lockfile.\n  - Run npm audit --json --audit-level=moderate and archive JSON artifact.[3][4]\n  - Parse JSON to normalized schema; fail PR on high/critical or if new vulns exceed baseline threshold.[3]\n  - Post PR comment summary: counts by severity, top packages affected, suggested fixes (audit fix hints) with links.[3][4]\n- Optional matrix: run against both production and dev dependency sets.\n\n3) Secondary security scanner\n- Option A (Snyk): add snyk auth token in CI secrets, run snyk test --json and snyk monitor for trends; export JSON for ingestion. Supports SCA and basic code scanning.\n- Option B (OWASP ZAP): in staging deploy workflow, run baseline scan against key routes (public, login, admin) with allowlist; export report (JSON/XML). Treat findings as DAST class and track separately.\n- Make the scanner choice configurable via env (SECURITY_SCANNER=snyk|zap|none) to allow phased rollout.\n\n4) Data model and storage\n- New DB tables: security_findings(id, source, cve, title, package, affected_version, fixed_version, severity, path, kind[SCA|SAST|DAST], status, first_seen, last_seen, occurrences, recommendation, created_at, updated_at), security_runs(id, source, started_at, finished_at, commit_sha, branch, passed, counts_json, artifact_url).\n- Upsert strategy: key by source + cve + package + path; update last_seen and occurrences; auto-close status to resolved when fixed_version installed or not detected for 7 consecutive runs.\n\n5) Ingestion service\n- Add /internal/security/ingest endpoints (auth: admin-only, token scoped) to receive scanner JSON payloads and store normalized findings.\n- Provide a CLI script or CI step that posts artifacts to ingestion after each scan.\n\n6) Admin dashboard UI (leveraging existing admin panel)\n- New \"Security\" section with tabs: Overview, Dependencies, Findings, Recommendations, History.\n  - Overview: total/open by severity, trend chart 30/90 days, SLA breaches.\n  - Dependencies: top packages by risk, updates available (minor/major), suggested actions (audit fix, replace library).[4]\n  - Findings: filterable table (status, severity, source, cve, package, first/last seen, age, recommendation). Row detail shows dependency tree path and remediation steps.[2][4]\n  - Recommendations: prioritized queue by severity, exploit maturity, time-to-fix, usage frequency.\n  - History: list of security_runs with pass/fail and artifact links.\n- Add actions: mark as in-progress/resolved (with reason), create issue link, export CSV for audits.\n\n7) Policies and SLAs\n- Define failure gates: block merges on critical/high; warn on moderate with aging >14 days; nightly scan posts Slack/email digest.\n- Define SLA: critical 3 days, high 7 days, moderate 30 days, low 90 days; surface breaches in UI and notifications.\n\n8) Developer workflow\n- Pre-merge checklist: run npm audit locally; commit lockfile updates when safe.[3][4]\n- For non-auto-fixable: open tracking issue with details and remediation notes; consider package replacement for persistent high/critical.[5]\n\nSecurity & Privacy\n- Store only necessary metadata (no secrets). Ensure admin-only access to security pages and ingestion endpoints, reusing existing role checks.\n- Mask tokens in logs; attach correlation IDs from existing logging module for traceability.\n\nOperationalization\n- Schedule nightly scans; create baseline record to measure net new findings. Add feature flag to disable failing builds temporarily.\n- Provide runbooks for typical remediations (upgrade, pin, replace) and exceptions (risk acceptance with expiration).\n",
        "testStrategy": "Automated\n- CI: Intentionally add a vulnerable dependency version; verify CI fails on high/critical with clear summary and artifact uploaded. Adjust --audit-level to moderate and confirm PR fails/passes as expected.[3]\n- CI to DB: After a scan, confirm ingestion endpoint receives JSON, creates/updates security_runs and security_findings, and upserts by source+cve+package+path.\n- Auto-resolve: Mark a finding open, upgrade dependency, rerun scans; verify status flips to resolved and last_seen updates.\n- Baseline: Create baseline of existing vulns; add one new high severity; confirm CI fails for net new only and admin UI highlights delta.\n- Notifications: Simulate nightly run with 2 SLA breaches; verify Slack/email digest content and counts.\n\nAdmin UI\n- Permissions: Non-admin cannot access Security pages (403); admin can view all tabs (reuses role checks from auth task).\n- Overview: Verify counts by severity match DB; trend chart reflects last 30 days of security_runs.\n- Findings table: Filter by severity, status, source; open detail and verify dependency path, remediation, and links render.\n- Actions: Change status to in-progress/resolved; confirm audit trail event created and DB updated.\n- Exports: Download CSV and validate schema and values.\n\nScanner-specific\n- npm audit JSON parsing: Feed a saved npm audit --json output; verify correct normalization of severity, package, versions, and recommendations.[4]\n- Snyk/ZAP option: Toggle SECURlTY_SCANNER to snyk, zap, none and validate pipeline behavior and ingestion.\n\nRegression & Reliability\n- Run scans on feature branches and main; ensure only main triggers nightly job and historical trends.\n- Load: Ingest 2k findings; UI remains responsive and queries indexed.\n- DR: Take backup/restore and ensure security tables present and restorable.\n",
        "status": "done",
        "dependencies": [
          2,
          3,
          8,
          9
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 21,
        "title": "Build Real-Time Security Dashboard in Admin Panel",
        "description": "Create an admin security dashboard that visualizes real-time code coverage, vulnerability counts by severity, dependency update status, failed security checks, and actionable recommendations with interactive charts, filtering, and drill-down views.",
        "details": "Scope and objectives:\n- Deliver a comprehensive, role-restricted Security dashboard within the Admin panel that aggregates metrics from CI scans, code coverage reports, and dependency status to monitor security posture in near real time.\n- Provide interactive charts, filters (time range, severity, status, source), and drill-down into underlying findings and affected assets.\n\nData sources and ingestion:\n- Coverage: Consume coverage-summary JSON and lcov artifacts produced by Jest coverage jobs; persist snapshots with timestamp, repo SHA, branch, and per-package metrics (statements, branches, lines, functions).\n- Vulnerabilities: Ingest normalized findings from security scanners (e.g., npm audit, Snyk/OWASP ZAP) already collected by existing scanning pipelines; store severity, package/component, CVE/ID, path, introduced version, fixed-in, status (open/ignored/resolved), first_seen, last_seen, and aging metadata.\n- Dependency status: Track outdated dependencies from CI (e.g., npm outdated JSON) and SCA results; derive counts by patch/minor/major and stale-age buckets.\n- Failed security checks: Persist CI policy gate results (e.g., high/critical found, coverage threshold breach, DAST alerts) with workflow run metadata for correlation.\n- Recommendations: Generate prioritized remediation items from scanning outputs and heuristics (e.g., upgrade to fixed versions, enable headers, fix ZAP alerts); store with impact, effort, and linked evidence.\n\nBackend/API design:\n- Create REST endpoints under /api/admin/security (RBAC: Admin only):\n  - GET /metrics?from=&to=&branch=&severity=: Returns aggregated counters and timeseries for coverage, vulns, dependency status, failed checks.\n  - GET /vulnerabilities?severity=&status=&source=&package=&hasFix=&page=&pageSize=: Paginated list with sorting and export flag; include drill-down fields.\n  - GET /coverage?from=&to=&package= and GET /coverage/:id: Timeseries and detail for snapshots with diff vs previous.\n  - GET /dependencies/outdated?scope=&semverImpact=&ageBucket=: Outdated packages with upgrade recommendations.\n  - GET /checks/failures?from=&to=&type=: CI policy failures with links to runs.\n  - GET /recommendations?status=&area=: Prioritized items with evidence and quick actions.\n- Implement query parameter validation, pagination, caching headers (ETag/Last-Modified), and index-backed queries (e.g., on timestamp, severity, status) for responsiveness.\n- Webhook/ingestion endpoints (internal): /api/admin/security/ingest/coverage, /ingest/vulns, /ingest/deps, /ingest/checks; authenticate via signed tokens from CI; enforce strict JSON schema validation.\n\nFrontend/UI implementation:\n- Location: Admin > Security.\n- Layout:\n  - KPI header: total open vulns by severity, current overall coverage %, number of outdated dependencies by impact (major/minor/patch), failed checks in last 7 days.\n  - Charts:\n    - Vulnerabilities by severity stacked bar with time brushing; click to filter.\n    - Coverage trend line (overall + per-package toggle) with threshold markers; tooltip shows diff vs previous.\n    - Dependency freshness donut by semver impact and bar by age bucket.\n    - Failed checks timeline with drill-down to workflow runs.\n  - Tables with drill-down:\n    - Vulnerabilities table: sortable columns (severity, package, version, CVE, source, has fix, age, status). Row click opens side panel with details, affected paths, and remediation steps.\n    - Outdated dependencies table: current vs latest, semver impact, risk tags, one-click copy of upgrade command.\n    - Recommendations list: impact vs effort matrix; bulk mark as accepted/ignored with reason codes.\n- Interactions:\n  - Global filters: time range (24h, 7d, 30d, custom), severity, source (SCA/SAST/DAST), status, branch/env (staging/prod).\n  - Drill-down preserves filter context and supports deep links (URL query state).\n  - Auto-refresh toggle (e.g., 30/60/300s) with backoff; visual \"live\" indicator.\n  - Export: CSV/JSON for tables; PNG for charts; print-friendly report snapshot.\n- Accessibility and performance:\n  - Keyboard navigation and ARIA labels; color-safe severity palette.\n  - Virtualized tables for large datasets; client-side caching; skeleton loaders.\n\nSecurity and compliance:\n- Enforce RBAC (admin-only) and audit logging for sensitive actions (status changes, ignore/accept decisions) without storing PII.\n- Protect ingestion endpoints with HMAC-signed requests and replay protection (nonce + timestamp); rate limit and validate payloads.\n- Do not expose raw secrets or internal file paths; mask repository/user identifiers as needed.\n\nData model (suggested tables/collections):\n- security_coverage_snapshots(id, ts, branch, sha, package, statements, lines, functions, branches, thresholds_ok)\n- security_vulnerabilities(id, ts_first_seen, ts_last_seen, severity, source, package, component_path, cve_id, introduced, fixed_in, status, notes)\n- security_dependency_outdated(id, ts_detected, package, current, latest, semver_impact, age_days, has_breaking_changes)\n- security_checks(id, ts, type, result, workflow_url, branch, sha, details)\n- security_recommendations(id, ts_created, area, title, impact, effort, evidence_ref, status)\n\nTech choices:\n- Reuse existing chart libs in the project (e.g., Tremor/Recharts) for consistency; implement polling via SWR/React Query with stale-while-revalidate.\n- Server-side: add indexes on ts, severity, status; aggregate queries with window functions for timeseries.\n\nOperational considerations:\n- Seed with historical imports from existing scan artifacts to populate baseline.\n- Feature flag the dashboard rollout; add usage telemetry to tune refresh intervals.\n- Document API contracts and payload schemas; provide CI examples for posting artifacts.\n",
        "testStrategy": "API verification:\n- Ingestion security: Send signed request with valid HMAC and timestamp to /ingest endpoints; expect 2xx and row creation. Replay same nonce; expect 409/Rejected. Send invalid signature; expect 401.\n- Schema validation: Post payloads missing required fields; verify 400 with clear errors and no data persisted.\n- Aggregations: Insert synthetic data covering all severities and time buckets; call GET /metrics with filters and validate counts and timeseries match ground truth.\n- Pagination/sorting: Verify /vulnerabilities and /dependencies endpoints return deterministic ordering, support page/pageSize, and enforce max pageSize.\n- Caching: Confirm ETag/Last-Modified present; conditional GET returns 304 when unchanged.\n\nUI verification:\n- RBAC: Non-admin user cannot access Admin > Security (403/redirect). Admin sees dashboard.\n- Filters: Changing global filters updates all widgets consistently; URL reflects state; a refresh restores same state.\n- Interactivity: Clicking severity bar filters table; drill-down side panel shows full details; navigating back preserves context.\n- Auto-refresh: With synthetic updates every 30s, charts and KPIs refresh without page reload; verify backoff when tab hidden.\n- Accessibility: Keyboard tab order covers all interactive elements; charts have descriptive labels; color contrast passes WCAG AA.\n- Export: Export CSV/JSON from tables and PNG from charts; files include current filters in metadata.\n\nData integrity and history:\n- Coverage trend: After posting three coverage snapshots, line chart shows correct progression and threshold markers; dropping below threshold triggers a visible warning badge.\n- Vulnerability lifecycle: Mark a vuln as ignored/resolved; status changes persist, audit log captures actor/time, and counts update.\n- Dependency aging: Verify age bucket calculations (e.g., 0–30, 31–90, 91+ days) and semver impact grouping.\n",
        "status": "done",
        "dependencies": [
          16,
          19,
          20
        ],
        "priority": "high",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-08-11T04:52:53.442Z",
      "updated": "2025-08-11T05:03:41.398Z",
      "description": "Security audit, hardening, and vulnerability assessment work"
    }
  },
  "feature-payment-system-enhancement": {
    "tasks": [
      {
        "id": 1,
        "title": "Plan architecture, stack, and security baseline",
        "description": "Define the technical approach for frontend, backend, database, storage, security, and deployment to meet PRD and current best practices.",
        "details": "- Frontend: Vanilla JS (ES2022), semantic HTML, CSS with mobile-first responsive layout, WCAG 2.1 AA. No frameworks. Use progressive enhancement and CSP.\n- Backend: Node.js 20 LTS, Express 4.19+, zod 3.23 for validation, multer 1.4 for uploads, sharp 0.33 for image processing, helmet 7, cors 2, pino 9 for logging, rate-limiter-flexible 5 for rate limiting.\n- AuthZ/AuthN: Use existing admin auth; if JWT, use jose 5; enforce RBAC “admin”.\n- DB: PostgreSQL 15+ (Neon). Use UUID (uuid-ossp or gen_random_uuid()). Migrations with Prisma 5.16 or Knex 3.1; recommend Prisma for schema, validation, and type safety.\n- Storage: Store QR images in /public/zelle-standardized and optionally S3-compatible (R2/S3) for future scalability. Keep only relative path in DB.\n- Security: TLS everywhere, strict CSP, input validation (zod), output encoding, sanitize filenames, verify Stripe URLs with allowlist patterns, audit logging for payment changes, soft deletes, encryption-at-rest for backups. Don’t store card data; use Stripe-hosted links to minimize PCI scope[2][1][5].\n- Performance: Image optimization (sharp, responsive sizes), HTTP caching (ETag, Cache-Control), CDN via Vercel static assets, DB indexes.\n- Monitoring: pino logs, route metrics (Prometheus-style if available), Vercel/Neon observability.\n- Deployment: Vercel for frontend/static, API via Vercel serverless or existing Node server; environment variables via Vercel/Neon.\n- Anti-AI training: add X-Robots-Tag: noai, noimageai; meta name=\"robots\" content=\"noai\".",
        "testStrategy": "Review architecture doc with stakeholders. Security checklist vs PCI DSS-relevant controls (tokenization via Stripe-hosted links; no PAN stored)[2]. Validate CSP headers in dev tools. Confirm log redaction and rate limiting. Smoke deploy to staging.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Draft end-to-end architecture and data flow",
            "description": "Produce a system architecture document covering frontend, backend, database, storage, CDN, and deployment topology aligned to the PRD and current best practices.",
            "dependencies": [],
            "details": "Define component boundaries (frontend static on Vercel, API on Vercel serverless or existing Node server), request/response flows, data contracts, and caching layers. Map how payment data and images move through the system, including Stripe-hosted links to avoid PCI scope. Include service diagram, environment layout (dev/staging/prod), and logging/observability surfaces.\n<info added on 2025-08-12T19:15:28.719Z>\nAdd payment system architecture plan:\n\n- Database: extend booster_clubs with payment fields: stripe_donation_link, stripe_membership_link, stripe_fees_link, payment_instructions (text), is_payment_enabled (boolean), zelle_qr_path (text), zelle_display_name (optional), last_payment_update_by, last_payment_update_at. Enforce NOT NULL defaults where applicable and indexes on (is_active, is_payment_enabled).\n\n- Backend/API: keep Node.js/Express on Vercel serverless for CRUD of payment links and public read of payment options. Admin endpoints under /api/admin/booster-clubs/:id/payment-links with zod validation and RBAC “admin”. Public endpoint /api/booster-clubs/:id/payment-options returns only safe fields. Use Stripe-hosted links only to avoid PCI scope; never handle card data. Log to pino with redaction of URLs’ query params; write PaymentAudit entries.\n\n- Frontend: refactor payment page to dynamically load per-club options. Render Zelle QR from Vercel Blob/public path, Stripe buttons for donation/membership/fees when present, and sanitized payment instructions. Ensure accessible labels and mobile-responsive images.\n\n- Storage: continue Vercel Blob for uploads; standardized Zelle QR derivatives stored at public/zelle-standardized/{club-slug}.png with 320/480/640 variants for srcset. Store file path in DB.\n\n- Caching: cache GET /api/booster-clubs/:id/payment-options at the edge with s-maxage=300, stale-while-revalidate=600. Invalidate by bumping last_payment_update_at ETag; clients use If-None-Match. Disable cache for admin endpoints.\n\n- Security baseline: CSP updated to allow https://buy.stripe.com and https://donate.stripe.com. Validate/normalize all URLs to https and allowed hosts. Sanitize payment_instructions server-side. Rate-limit public and admin endpoints. Maintain audit trail and ensure no PAN, tokens, or webhook secrets are stored beyond Stripe links.\n\n- Environments: dev/staging/prod with separate Neon databases and Blob buckets. Feature flags to toggle payment page per env.\n\n- Observability: structured logs for payment option reads/updates with club_id and outcome; metrics for cache hit rate and endpoint latency; alerts on validation failures or unusually frequent updates.\n\n- Diagrams: update service diagram to include payment flows: Client -> Public API payment-options -> DB; Admin -> Admin API payment-links -> DB + Audit; Client -> Stripe-hosted pages; Client -> Zelle via scanned QR (out of band). Add environment layout showing Blob/Neon per env.\n\n- Testing: expand existing Jest/Playwright suites to cover payment link validation, admin CRUD, public rendering states, a11y, and security tests (SSRF/XSS).\n</info added on 2025-08-12T19:15:28.719Z>",
            "status": "done",
            "testStrategy": "Architecture review with stakeholders; verify flows satisfy PRD use cases; confirm no PAN storage and Stripe links usage to minimize PCI scope."
          },
          {
            "id": 2,
            "title": "Select and pin stack versions with security baselines",
            "description": "Confirm runtime/framework/library versions and codify security controls and headers for Express/Node and frontend.",
            "dependencies": [
              "1.1"
            ],
            "details": "Lock Node.js 20 LTS and Express 4.19+ or newer to avoid known CVEs such as open redirect issues; enable Helmet, CORS, rate limiting, secure dependencies policy, and TLS; define CSP, X-Content-Type-Options, and other headers. Document dependency update and auditing process (npm audit/Snyk).\n<info added on 2025-08-12T19:17:14.358Z>\nUpdate secure version pins and controls:\n\n- Node.js: pin to latest 20.x LTS (20.17.x or newer) and track ongoing 2025 security releases; enable Node permission model in production where feasible.\n- Express: >= 4.21.x with Sept 2024 security patches (CVE-2024-43796, CVE-2024-43799, CVE-2024-43800, CVE-2024-45296). Explicitly prohibit Express 3.x in any dependency tree.\n- body-parser: >= 1.20.3 (fixes CVE-2024-45590 DoS).\n- Validation: zod 3.23.x; enforce strict input schemas.\n- Uploads: multer latest 1.4.x configured with memoryStorage, 1 MB max, MIME allowlist, and magic-byte verification; block double extensions and enforce deterministic filenames.\n- Imaging: sharp 0.33.x (libvips security fixes); strip metadata and normalize images.\n- Security middleware: helmet 7.x with strict CSP; cors 2.x with explicit origin allowlist; rate-limiter-flexible 5.x with tighter limits on admin routes.\n- Logging: pino 9.x with PII redaction; ensure audit logging for admin actions.\n- Network egress: URL allowlist for Stripe only: buy.stripe.com and donate.stripe.com; block SSRF and disallow javascript:, data:, file: schemes.\n- TLS/HTTPS: enforce HTTPS-only, HSTS, secure cookies, and disable insecure ciphers.\n- Dependency hygiene: pin exact versions, run npm audit and Snyk weekly; fail CI on high/critical issues; schedule monthly dependency review.\n- Add Stripe domain regex to validation layer and apply to payment link endpoints.\n- Document configuration snippets for CSP, CORS origins, rate limits, pino redaction, and multer/sharp defaults.\n- Next actions: update package.json to these versions and commit security configuration modules (headers, CORS, rate limiter, logging redaction, upload policy).\n</info added on 2025-08-12T19:17:14.358Z>",
            "status": "done",
            "testStrategy": "Validate headers in devtools; run npm audit/Snyk; verify rate limiting and CORS behavior; confirm Express version meets fixed advisories."
          },
          {
            "id": 3,
            "title": "Database schema, migrations, and storage plan",
            "description": "Design PostgreSQL schema with UUIDs, soft deletes, indexes, and audit tables; define image storage layout and paths.",
            "dependencies": [
              "1.1"
            ],
            "details": "Use Prisma migrations; choose gen_random_uuid(); define tables for clubs, payment links, and payment audit logs; store only relative paths for QR images; plan optional S3-compatible storage integration; specify retention and backup (Neon PITR) policies.\n<info added on 2025-08-12T19:20:10.162Z>\nUpdates applied:\n\n- Implemented Prisma migration adding eight payment-related fields to booster_clubs, with gen_random_uuid() UUID PKs and FK relationships.\n- Created payment_audit_log table and PostgreSQL trigger for automatic before/after change capture on payment fields.\n- Added performance indexes for frequent payment queries.\n- Enforced data integrity: Stripe URL regex allowlist, length limits, and non-null/enum constraints where applicable.\n- Verified rollback safety and added verification steps for migrations.\n\nStorage plan finalized (docs/STORAGE_PLAN.md):\n\n- File organization structure defined; QR images stored as relative paths only.\n- Image processing via Sharp.js with responsive variants and metadata stripping.\n- Integration strategy for Vercel Blob; optional S3-compatible storage retained.\n- Security controls: strict access policies, safe file naming, and public/private separation.\n- Backup and recovery documented, aligned with Neon PITR retention policies.\n- Cost and performance estimates included.\n\nKey features delivered:\n\n- UUID-based primary keys with proper foreign key relationships.\n- Comprehensive audit trail for all payment-related changes.\n- Stripe URL validation using approved regex patterns.\n- Secure file naming and storage strategy.\n- Performance optimizations through targeted indexing.\n- Full rollback capability and verification procedures.\n\nReady to proceed to Subtask 1.4: Security and compliance checklist.\n</info added on 2025-08-12T19:20:10.162Z>",
            "status": "done",
            "testStrategy": "Apply migrations in staging; confirm audit insertions on updates; verify indexes via EXPLAIN; test backup/restore drill on a small dataset."
          },
          {
            "id": 4,
            "title": "Security and compliance checklist",
            "description": "Create a concrete checklist covering input validation, output encoding, SSRF/XSS protections, Stripe URL allowlist validation, logging redaction, and PCI-relevant controls.",
            "dependencies": [
              "1.2",
              "1.3"
            ],
            "details": "Standardize zod validation schemas, sanitize filenames, enforce HTTPS and strict CSP, define RBAC admin role, redact PII in logs, add anti-AI training headers/meta, document encryption-at-rest for backups, and Stripe link allowlist patterns with normalization.",
            "status": "done",
            "testStrategy": "Run through checklist in staging; pen-test URL validation and XSS vectors; verify audit logging captures before/after for payment updates."
          },
          {
            "id": 5,
            "title": "Deployment, observability, and rollback plan",
            "description": "Define environment variables, CI/CD steps, safe migrations, logging/metrics, caching/CDN, and rollback procedures.",
            "dependencies": [
              "1.2",
              "1.3",
              "1.4"
            ],
            "details": "Configure Vercel projects, env secrets (DATABASE_URL, Stripe allowlist, JWT settings, LOG_LEVEL), prisma migrate deploy on release, blue/green or staged rollout, ETag/Cache-Control for APIs and static assets, pino logging with request IDs, metrics if available, Neon observability and PITR.",
            "status": "done",
            "testStrategy": "Automated deploy to staging on main; verify migrations run; smoke tests; test rollback by revert and redeploy; confirm logs/metrics visible and cache headers applied."
          }
        ]
      },
      {
        "id": 2,
        "title": "Database migration for payment fields and audit trail",
        "description": "Extend booster_clubs table with payment fields and create audit trail + soft delete support.",
        "details": "- Using Prisma: add fields to BoosterClub model: zelleQrCodePath (String?), stripeDonationLink (String?), stripeMembershipLink (String?), stripeFeesLink (String?), paymentInstructions (String? @db.Text), isPaymentEnabled (Boolean @default(false)). Add updatedAt, deletedAt (DateTime?).\n- Create PaymentAudit table: id UUID PK, boosterClubId UUID FK -> booster_clubs(id), action (TEXT), before (JSONB), after (JSONB), actor (TEXT), createdAt TIMESTAMP DEFAULT now(). Index on boosterClubId, createdAt.\n- Add partial indexes: CREATE INDEX ON booster_clubs((lower(name))) WHERE deleted_at IS NULL; and individual indexes on is_payment_enabled.\n- Ensure FK constraints with ON UPDATE CASCADE, ON DELETE RESTRICT.\n- Use gen_random_uuid() (pgcrypto) for UUIDs if needed.\n- Migration scripts: forward/backward.\n- Seed script to backfill is_payment_enabled=false for all.",
        "testStrategy": "Run migration in staging. Verify schema diff. Insert test club and audit record. Ensure referential integrity and indexes exist. Rollback test. Check query plans for new indexes.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Prisma schema changes for booster_clubs and PaymentAudit",
            "description": "Update schema.prisma to add payment fields, soft-delete timestamps, and audit table with required indexes and constraints.",
            "dependencies": [],
            "details": "In BoosterClub model, add: zelleQrCodePath String?, stripeDonationLink String?, stripeMembershipLink String?, stripeFeesLink String?, paymentInstructions String? @db.Text, isPaymentEnabled Boolean @default(false), updatedAt DateTime @updatedAt, deletedAt DateTime?. Create PaymentAudit model: id String @id @default(dbgenerated(\"gen_random_uuid()\")) @db.Uuid, boosterClubId String @db.Uuid, action String, before Json, after Json, actor String, createdAt DateTime @default(now()). Add relation: boosterClub BoosterClub @relation(fields: [boosterClubId], references: [id], onUpdate: Cascade, onDelete: Restrict). Add indexes: @@index([boosterClubId, createdAt]), @@index([createdAt]). For booster_clubs, ensure @@index([isPaymentEnabled]). Note: Use @@map to match existing table names if they differ (e.g., booster_clubs).\n<info added on 2025-08-12T19:33:25.720Z>\nScope revision: This migration should drop any fields or tables related to direct payment processing and limit the schema to link storage and link-change auditing. Update plan:\n- Keep only link-related fields on BoosterClub: zelleQrCodePath, stripeDonationLink, stripeMembershipLink, stripeFeesLink, paymentInstructions, isPaymentEnabled, updatedAt, deletedAt. Do not add any columns for processing details, transactions, or payer data.\n- Simplify PaymentAudit to track only link management changes: fields = id (UUID), boosterClubId (UUID FK), before (JSONB), after (JSONB), actor (TEXT), createdAt (TIMESTAMP DEFAULT now()). Remove action string and any payment-event specific fields. Audit rows should be written only when link fields or paymentInstructions/isPaymentEnabled are created/updated/cleared.\n- Indexes: on payment_audit, keep @@index([boosterClubId, createdAt]) and @@index([createdAt]) for chronological lookups per club. On booster_clubs, keep @@index([isPaymentEnabled]) for filtering enabled clubs. No partial index for payment processing states since none are stored.\n- Clarify intent with comments in schema: “Link redirection only; no payment processing or sensitive payment data stored.”\n</info added on 2025-08-12T19:33:25.720Z>\n<info added on 2025-08-12T19:37:16.534Z>\nAdmin Panel scope alignment for indexes and audits: Although the admin panel will provide comprehensive payment management (dashboard, Zelle QR processing from DOCX with URL extraction and QR generation, Stripe link management with bulk ops, and rich-text payment instructions), the database migration remains link-storage only. Ensure all admin features write PaymentAudit rows exclusively when modifying link fields, paymentInstructions, or isPaymentEnabled; no transaction, payer, or processing state data is added to the schema. No partial indexes will be introduced for processing states; retain only @@index([boosterClubId, createdAt]) and @@index([createdAt]) on payment_audit and @@index([isPaymentEnabled]) on booster_clubs. Include schema comments reinforcing: “Admin manages links/QR assets and instructions; database stores links and audit entries only—no payment processing or sensitive payment data.”\n</info added on 2025-08-12T19:37:16.534Z>\n<info added on 2025-08-12T19:40:33.732Z>\nScope clarification for seeding and admin UI: The QRCODES4BOOSTERS.docx ingestion is a one-time seeding step to extract Zelle URLs and write standardized QR image paths into zelleQrCodePath; it is not part of ongoing admin workflows. The admin will manage Zelle QR image upload and Stripe links together on a single page at /admin/payment-settings.html per club—no document upload UI. Ensure the migration and audit rules remain link-storage only: seeding writes initial zelleQrCodePath values, and subsequent admin edits (QR upload, Stripe links, paymentInstructions, isPaymentEnabled) create PaymentAudit entries; no transaction or processing state is stored. Include a schema comment reinforcing that DOCX extraction is seeding-only and ongoing management is via individual field updates on the combined payment settings page.\n</info added on 2025-08-12T19:40:33.732Z>",
            "status": "done",
            "testStrategy": "Run prisma validate to ensure schema is consistent. Verify relation attributes align with ON UPDATE CASCADE and ON DELETE RESTRICT. Confirm UUID default compiles using pgcrypto."
          },
          {
            "id": 2,
            "title": "Author SQL migration for indexes and partial index",
            "description": "Create custom migration SQL implementing partial index on lower(name) for non-deleted records and dedicated index on is_payment_enabled.",
            "dependencies": [
              "2.1"
            ],
            "details": "Within the generated migration.sql, append: CREATE EXTENSION IF NOT EXISTS pgcrypto; CREATE INDEX IF NOT EXISTS idx_booster_clubs_lower_name_active ON booster_clubs ((lower(name))) WHERE deleted_at IS NULL; CREATE INDEX IF NOT EXISTS idx_booster_clubs_is_payment_enabled ON booster_clubs (is_payment_enabled); Ensure PaymentAudit table creation with id UUID DEFAULT gen_random_uuid(), created_at DEFAULT now(), FK to booster_clubs(id) ON UPDATE CASCADE ON DELETE RESTRICT, and indexes on (booster_club_id, created_at) and (created_at).",
            "status": "done",
            "testStrategy": "Apply migration to a local Postgres. Inspect indexes via \\d booster_clubs and \\d payment_audit. Check partial index predicate and operator class. Validate FK actions using pg_get_constraintdef."
          },
          {
            "id": 3,
            "title": "Generate forward and backward Prisma migrations",
            "description": "Produce forward migration to apply schema changes and a rollback migration to revert them safely, following Prisma Migrate best practices.",
            "dependencies": [
              "2.1",
              "2.2"
            ],
            "details": "Run npx prisma migrate dev --name add-payment-fields-and-audit to generate forward migration, customizing SQL as needed. Create a corresponding down script section (manual SQL notes) to drop added columns, indexes, and PaymentAudit table in reverse order. Ensure contract stage notes are documented if future cleanup is needed.",
            "status": "done",
            "testStrategy": "Apply migration on a staging clone, then run npx prisma migrate reset or manual down migration to ensure clean rollback. Verify no data loss beyond introduced columns/tables."
          },
          {
            "id": 4,
            "title": "Data backfill and seed script for isPaymentEnabled",
            "description": "Implement a one-time script to backfill is_payment_enabled=false for all existing booster clubs and wire it into package.json.",
            "dependencies": [
              "2.3"
            ],
            "details": "Create scripts/prisma/backfill-is-payment-enabled.ts using PrismaClient to updateMany({ data: { isPaymentEnabled: false } }). Add npm script: \"seed:backfill:payments\": \"tsx scripts/prisma/backfill-is-payment-enabled.ts\". Wrap in a transaction and log affected row count. Idempotent: only set nulls to false if column may exist with nulls; if not, still safe.",
            "status": "done",
            "testStrategy": "Run against staging with dry-run mode first (SELECT count WHERE is_payment_enabled IS DISTINCT FROM false). Execute and verify count becomes 0 for non-false states. Re-run to confirm idempotency."
          },
          {
            "id": 5,
            "title": "Verification checklist and query plan validation",
            "description": "Validate schema diff, referential integrity, and index usage for typical queries; document results.",
            "dependencies": [
              "2.3",
              "2.4"
            ],
            "details": "Insert a test booster club and corresponding PaymentAudit row; verify FK constraints and ON DELETE RESTRICT. Ensure soft-delete flows by setting deleted_at and confirming partial index excludes the row. Run EXPLAIN ANALYZE on queries filtering WHERE deleted_at IS NULL AND lower(name)=..., and WHERE is_payment_enabled=true to confirm index hits. Confirm updatedAt auto-updates on record modification.",
            "status": "done",
            "testStrategy": "Use SQL EXPLAIN ANALYZE and Prisma logs to verify index usage; write a small script to mutate BoosterClub and ensure updatedAt changes; attempt deleting a referenced booster club to confirm restriction; roll back and re-apply migration as a final integrity check."
          }
        ]
      },
      {
        "id": 3,
        "title": "Secure file upload pipeline for Zelle QR images",
        "description": "Implement backend upload endpoint with validation, image processing, and safe storage for QR code images.",
        "details": "- Endpoint: POST /api/admin/booster-clubs/:id/zelle-qr (admin only).\n- Use multer with memoryStorage, limit file size (<= 1 MB) and accept image/png,image/jpeg only.\n- Use sharp to normalize: convert to PNG, resize to max 640x640, strip metadata, set quality (png compressionLevel=9). Generate deterministic filename: zelle-standardized/{club-slug}.png.\n- Write to public/zelle-standardized directory; ensure directory exists. Optionally upload to S3 if configured; store relative path in DB.\n- Sanitize slug, prevent path traversal. Set Cache-Control: public, max-age=31536000, immutable for static.\n- Update booster_clubs.zelle_qr_code_path and create PaymentAudit entry.",
        "testStrategy": "Upload various files (valid/invalid types, oversized). Attempt path traversal filenames. Verify output size, format, and that EXIF is stripped. Confirm DB updated and audit trail created. Manual scan QR to ensure readability across devices (iOS/Android).",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design endpoint, auth, and validation contract",
            "description": "Define POST /api/admin/booster-clubs/:id/zelle-qr with admin-only access, request field names, and validation rules (file required, <=1 MB, image/png or image/jpeg, club :id exists and admin authorized).",
            "dependencies": [],
            "details": "Specify middleware order: auth -> param validation -> multer(memoryStorage) with limits and fileFilter -> controller. Document accepted form field name (e.g., 'file'), error responses (problem+json), and redaction policy for logs.",
            "status": "pending",
            "testStrategy": "Hit endpoint without auth (401/403), with invalid :id (404/400), missing file (400), wrong mimetype (415), and oversized file (413)."
          },
          {
            "id": 2,
            "title": "Implement secure multer middleware with memoryStorage",
            "description": "Configure multer to buffer files in memory with size limit and strict MIME/type checks for PNG/JPEG only.",
            "dependencies": [
              "3.1"
            ],
            "details": "Use memoryStorage; set limits: { fileSize: 1_000_000 }. Implement fileFilter that checks both mimetype and signature (magic bytes) for PNG/JPEG; reject others with clear errors. Ensure only single file 'file' is accepted. Prevent DOS by limiting field counts and parts.",
            "status": "pending",
            "testStrategy": "Upload valid PNG/JPEG; attempt SVG, PDF, HEIC; attempt renamed non-image with image extension; confirm 413 for >1MB; verify req.file is defined only for valid cases."
          },
          {
            "id": 3,
            "title": "Image normalization pipeline with sharp",
            "description": "Process buffered upload with sharp: convert to PNG, resize to max 640x640 preserving aspect ratio, strip metadata, and set compressionLevel=9.",
            "dependencies": [
              "3.2"
            ],
            "details": "Use sharp(buffer).rotate().resize({ width: 640, height: 640, fit: 'inside', withoutEnlargement: true }).png({ compressionLevel: 9 }).withMetadata({ exif: undefined, icc: undefined }).toBuffer(). Ensure deterministic output. Validate final byte size and dimensions.",
            "status": "pending",
            "testStrategy": "Verify output format is PNG, max dimensions ≤640x640, EXIF removed, and that QR remains scannable by manual tests on iOS/Android."
          },
          {
            "id": 4,
            "title": "Deterministic filename, path safety, and storage",
            "description": "Generate zelle-standardized/{club-slug}.png safely; ensure directory exists; write to public/zelle-standardized; optionally upload to S3; set Cache-Control for static serving.",
            "dependencies": [
              "3.3"
            ],
            "details": "Sanitize slug to [a-z0-9-] only; reject or normalize others. Prevent path traversal by joining with fixed base and verifying path prefix. Ensure directory creation with fs.mkdir({ recursive: true }). If S3 configured, upload with key zelle-standardized/{slug}.png and Cache-Control: public, max-age=31536000, immutable; otherwise write locally and ensure static server sets same headers.",
            "status": "pending",
            "testStrategy": "Attempt malicious slugs (../, %2e%2e/); confirm safe path. Verify file exists and headers served with immutable caching. If S3, check object metadata and public accessibility per policy."
          },
          {
            "id": 5,
            "title": "Database update and audit logging",
            "description": "Persist relative path to booster_clubs.zelle_qr_code_path and create PaymentAudit entry including actor, club, and operation details.",
            "dependencies": [
              "3.4"
            ],
            "details": "On successful write/upload, store relative path like /zelle-standardized/{slug}.png. Wrap in transaction if needed. Emit PaymentAudit with type 'zelle_qr_upload', old_path/new_path, file hash (e.g., SHA-256), and IP/user agent from request context.",
            "status": "pending",
            "testStrategy": "Verify DB row updated correctly; ensure audit record created with accurate metadata. Update same club and confirm old/new path diff recorded. Check logs redact sensitive fields."
          }
        ]
      },
      {
        "id": 4,
        "title": "QR code extraction/generation from QRCODES4BOOSTERS.docx",
        "description": "Automate extraction of Zelle QR images from the provided DOCX and store with consistent naming.",
        "details": "- One-time script (Node): use mammoth 1.6 or docx 8.x to read DOCX and extract embedded images.\n- Map images to clubs via a CSV mapping file (club name -> image index/label). Output to public/zelle-standardized/{club-slug}.png.\n- Use sharp to normalize (PNG, 640x640) and optimize.\n- For clubs without QR, skip and mark missing.\n- Generate a report (JSON) of processed clubs and missing QR codes to feed admin bulk import.\n- Do not OCR or modify QR content to avoid damaging codes; only re-encode at high quality.",
        "testStrategy": "Run against sample DOCX; verify file count matches expected. Randomly scan a subset to confirm codes resolve. Validate filenames match slug rules. Verify missing list is accurate.",
        "priority": "medium",
        "dependencies": [
          3
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Parse DOCX and extract embedded images to temp directory",
            "description": "Implement a Node script to open QRCODES4BOOSTERS.docx and extract all embedded images to a deterministic temp folder while preserving original image buffers.",
            "dependencies": [],
            "details": "Use mammoth with a custom images handler to read the DOCX and write each image buffer to a temp path with sequential indexing to maintain stable ordering. Capture a manifest of {index, originalContentType, tempPath}. Mammoth supports image extraction via images handler returning buffer and writing files, ensuring reliable processing for DOCX without Office installed.[2][4][1]",
            "status": "pending",
            "testStrategy": "Run on a sample DOCX and assert that image count in temp equals images reported by mammoth messages; verify temp files exist and are readable."
          },
          {
            "id": 2,
            "title": "Load club mapping CSV and resolve target filenames",
            "description": "Parse the CSV mapping (club name -> image index/label) and generate normalized output paths public/zelle-standardized/{club-slug}.png.",
            "dependencies": [
              "4.1"
            ],
            "details": "Use a CSV parser to load mappings, slugify club names, and join against the extracted images by index or label from the manifest. Produce a list of planned outputs with full paths and back-references to temp images. Entries with missing indices are flagged for 'missing' handling.",
            "status": "pending",
            "testStrategy": "Validate that every CSV row yields either a resolvable image or a missing flag. Check slug formatting against project rules and ensure no duplicate slugs."
          },
          {
            "id": 3,
            "title": "Normalize and re-encode images with sharp",
            "description": "Convert matched images to optimized PNGs at 640x640, avoiding any QR content modification beyond lossless-like re-encode.",
            "dependencies": [
              "4.2"
            ],
            "details": "Use sharp to load the temp image buffer, resize to exact 640x640 with appropriate interpolation (e.g., nearest or mitchell for QR clarity), strip metadata, and output PNG with compressionLevel=9. Preserve visual fidelity to avoid damaging QR readability. Save to public/zelle-standardized/{club-slug}.png as specified.",
            "status": "pending",
            "testStrategy": "Spot-check a subset by scanning with a QR app to confirm readability. Verify output dimensions, format, and file size; ensure EXIF is stripped."
          },
          {
            "id": 4,
            "title": "Handle missing and skipped clubs and generate JSON report",
            "description": "Produce a machine-readable report listing processed clubs, file paths, and clubs without QR for admin bulk import.",
            "dependencies": [
              "4.2",
              "4.3"
            ],
            "details": "Create report JSON containing arrays: processed [{clubId/slug, path, sourceIndex}], missing [{clubId/slug, reason}], and stats (counts). Include any image extraction or mapping warnings from mammoth/messages for traceability.[2][4]",
            "status": "pending",
            "testStrategy": "Compare counts against CSV total and extracted image count. Validate JSON schema and that paths exist on disk for processed entries."
          },
          {
            "id": 5,
            "title": "One-time run script, safety checks, and cleanup",
            "description": "Wire up CLI script with dry-run, overwrite protection, idempotency, and temp directory cleanup.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.4"
            ],
            "details": "Add flags: --input DOCX, --csv mapping.csv, --outDir public/zelle-standardized, --dry-run, --force. Refuse to overwrite existing outputs unless --force. Ensure temp artifacts are deleted on success; retain on failure with a pointer in the report. Exit codes reflect success/partial/missing.",
            "status": "pending",
            "testStrategy": "Run dry-run to verify planned actions only. Execute full run twice to confirm idempotency and overwrite behavior. Ensure cleanup removes temp files on success and preserves on error."
          }
        ]
      },
      {
        "id": 5,
        "title": "Stripe link validation and storage endpoints",
        "description": "Add CRUD endpoints and validation for Stripe donation/membership/fees links per club.",
        "details": "- Endpoints (admin):\n  - PUT /api/admin/booster-clubs/:id/payment-links {stripeDonationLink?, stripeMembershipLink?, stripeFeesLink?, paymentInstructions?, isPaymentEnabled?}\n  - GET /api/admin/booster-clubs/:id/payment-links\n- Validate with zod: links must match allowlist regex: ^https://(buy\\.stripe\\.com|donate\\.stripe\\.com)/[A-Za-z0-9]+.*$ and no javascript: or data:.\n- Normalize by trimming, enforce https.\n- Store in respective DB columns. Write PaymentAudit entries with before/after.\n- Ensure secure headers (Helmet), rate limit, CSRF protection if using cookies.\n- Never proxy payment; only redirect to Stripe-hosted links to minimize PCI scope[2][1].",
        "testStrategy": "Unit tests for validation (good/bad URLs). Integration tests: create/update links, verify audit rows. Security tests: SSRF attempts, XSS in paymentInstructions sanitized (DOMPurify on frontend; sanitize-html on backend).",
        "priority": "high",
        "dependencies": [
          2,
          1
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Zod schemas and normalization for Stripe payment links",
            "description": "Create Zod schemas for admin payload and params. Enforce allowlist regex for Stripe Payment Links, forbid javascript: and data: schemes, trim inputs, and force https.",
            "dependencies": [],
            "details": "Define PaymentLinksSchema with optional fields: stripeDonationLink, stripeMembershipLink, stripeFeesLink, paymentInstructions, isPaymentEnabled. Validate links against ^https://(buy\\.stripe\\.com|donate\\.stripe\\.com)/[A-Za-z0-9]+.*$ and reject other schemes; normalize by trimming and converting http to https. Document Stripe-hosted Payment Links usage to minimize PCI scope per Stripe docs.[5]",
            "status": "pending",
            "testStrategy": "Unit tests: valid buy.stripe.com/donate.stripe.com links pass; invalid hosts fail; http auto-upgrades to https; javascript:/data: rejected; trailing/leading whitespace trimmed. Fuzz tests with long inputs. Mock examples per Stripe Payment Links behavior.[5]"
          },
          {
            "id": 2,
            "title": "Implement GET admin endpoint for retrieving payment links",
            "description": "Add GET /api/admin/booster-clubs/:id/payment-links to fetch existing Stripe links, payment instructions, and flags from DB with authZ checks.",
            "dependencies": [
              "5.1"
            ],
            "details": "Express route with RBAC admin check, param validation, and content-type application/json. Read from club columns and return JSON. Ensure output encoding and no HTML injection in JSON responses.",
            "status": "pending",
            "testStrategy": "Integration test: authorized admin receives 200 with expected fields; non-admin/unauth returns 403/401. Verify headers include JSON content-type and security headers via Helmet."
          },
          {
            "id": 3,
            "title": "Implement PUT admin endpoint with validation, normalization, and storage",
            "description": "Add PUT /api/admin/booster-clubs/:id/payment-links to create/update Stripe links and related fields with Zod validation and normalization.",
            "dependencies": [
              "5.1"
            ],
            "details": "Validate body using PaymentLinksSchema; normalize fields (trim, enforce https). Update respective DB columns in a transaction. Never proxy payments; only store and later redirect to Stripe-hosted links to minimize PCI scope.[5]",
            "status": "pending",
            "testStrategy": "Integration tests: update each field individually and together; verify DB reflects normalized values. Negative tests for invalid URLs/schemes rejected with 400 and no DB changes."
          },
          {
            "id": 4,
            "title": "Add PaymentAudit logging for before/after changes",
            "description": "Write audit entries capturing previous and new values for changed fields when PUT endpoint is called successfully.",
            "dependencies": [
              "5.3"
            ],
            "details": "Within the same transaction as the update, insert PaymentAudit rows including userId, clubId, changed fields, before/after snapshots, timestamp, and route. Redact sensitive or large text in logs; keep audit table authoritative.",
            "status": "pending",
            "testStrategy": "Integration tests: perform updates and assert PaymentAudit row exists with accurate before/after diffs and correct user/route metadata. Ensure no audit row on validation failure or no-op update."
          },
          {
            "id": 5,
            "title": "Security hardening: headers, rate limiting, CSRF, and SSRF/XSS defenses",
            "description": "Ensure admin routes use Helmet, rate limits, CSRF protection (if cookies), and sanitize paymentInstructions on backend. Block SSRF and only allow Stripe-hosted link patterns.",
            "dependencies": [
              "5.2",
              "5.3"
            ],
            "details": "Enable Helmet (HSTS, frameguard DENY, noSniff). Apply per-IP and per-user rate limiting to admin routes. If cookie-based auth, add CSRF middleware; otherwise require anti-CSRF token. Sanitize paymentInstructions with sanitize-html allowlist. Enforce allowlist URL regex to prevent SSRF and only redirect to Stripe Payment Links.[5]",
            "status": "pending",
            "testStrategy": "Security tests: simulate CSRF request and ensure blocked; verify headers present; rate limit triggers after threshold; XSS payloads in paymentInstructions are sanitized; SSRF attempts via non-Stripe URLs rejected. Manual check that redirects go to buy.stripe.com/donate.stripe.com only.[5]"
          }
        ]
      },
      {
        "id": 6,
        "title": "Public payment data read API",
        "description": "Create read-only API to fetch payment options for a given booster club for the payment page.",
        "details": "- Endpoint: GET /api/booster-clubs/:id/payment-options returns {clubId, name, isPaymentEnabled, zelleQrCodePath, stripeDonationLink, stripeMembershipLink, stripeFeesLink, paymentInstructions}.\n- Validate :id as UUID. Only returns for non-deleted clubs. Apply caching: Cache-Control: public, max-age=300; ETag.\n- Hide admin-only metadata.\n- Defensive encoding; serialize nulls when missing.\n- Pino logging with request ID; rate limit per IP.",
        "testStrategy": "Integration tests: existing club returns expected fields; deleted club 404; disabled returns isPaymentEnabled=false. Verify caching headers. Load test basic throughput.",
        "priority": "high",
        "dependencies": [
          2,
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define API contract and validation rules",
            "description": "Specify the exact response schema, status codes, and request validation for GET /api/booster-clubs/:id/payment-options, including UUID validation and behavior for deleted/disabled clubs.",
            "dependencies": [],
            "details": "Response fields: {clubId, name, isPaymentEnabled, zelleQrCodePath, stripeDonationLink, stripeMembershipLink, stripeFeesLink, paymentInstructions}. Status codes: 200 OK, 400 for invalid UUID, 404 for non-existent or soft-deleted club. Ensure admin-only metadata is excluded. Serialize nulls for missing optional fields. Define error format consistently with existing API standards.",
            "status": "done",
            "testStrategy": "Contract tests with example payloads; negative tests for invalid UUID and non-existent/deleted IDs; snapshot tests for field presence and null serialization."
          },
          {
            "id": 2,
            "title": "Implement data access with soft-delete and projection",
            "description": "Create repository/service layer to fetch booster club by ID, filter out soft-deleted rows, and project only public payment fields.",
            "dependencies": [
              "6.1"
            ],
            "details": "Query BoosterClub where id = :id and deletedAt IS NULL. Select only: id, name, isPaymentEnabled, zelleQrCodePath, stripeDonationLink, stripeMembershipLink, stripeFeesLink, paymentInstructions. Map id to clubId in DTO. Avoid loading admin metadata. Handle nulls explicitly in DTO.",
            "status": "done",
            "testStrategy": "Integration tests against a test DB: existing active club returns expected projection; soft-deleted club returns 404; disabled club returns isPaymentEnabled=false with other fields present/null as stored."
          },
          {
            "id": 3,
            "title": "Add HTTP layer with caching, logging, and rate limiting",
            "description": "Expose Express/Fastify route GET /api/booster-clubs/:id/payment-options with Pino request ID logging, per-IP rate limiting, Cache-Control and ETag headers, and defensive encoding.",
            "dependencies": [
              "6.2"
            ],
            "details": "Validate :id as UUID at the router. On 200, set Cache-Control: public, max-age=300 and compute strong ETag from JSON body hash; support If-None-Match to return 304. Use Pino child logger with requestId included in each log line. Apply IP-based rate limit (e.g., 60 req/min). Ensure JSON serialization includes nulls and escapes strings. Do not leak admin fields in any branch.",
            "status": "done",
            "testStrategy": "Supertest integration: verify headers Cache-Control and ETag present; conditional GET returns 304; logs include requestId; rate limit triggers 429 with retry headers. Fuzz test with unusual strings in paymentInstructions."
          },
          {
            "id": 4,
            "title": "Security and robustness hardening",
            "description": "Ensure endpoint does not expose sensitive data, implements input/output sanitization, and resists common abuse.",
            "dependencies": [
              "6.3"
            ],
            "details": "Enforce strict CORS policy for public read endpoint if applicable. Sanitize and HTML-encode output fields where needed to prevent injection in downstream clients; ensure URLs are returned as plain strings without transformation. Confirm no admin-only metadata is reachable via query params. Add circuit breakers/timeouts for DB calls and standardized error responses.",
            "status": "done",
            "testStrategy": "Security tests: attempt parameter pollution, large IDs, path traversal in id, overlong strings in DB. Static analysis/lint checks. Confirm no sensitive headers/fields in responses."
          },
          {
            "id": 5,
            "title": "Automated tests and monitoring",
            "description": "Finalize integration tests, add basic load tests, and wire metrics/alerts for availability and latency.",
            "dependencies": [
              "6.4"
            ],
            "details": "Integration tests: success, 400, 404, disabled club, caching headers, 304 flow. Load test: 200 RPS for 1 minute with 95th percentile latency target (<150ms) using cached responses. Add metrics (requests, 2xx/4xx/5xx counts, p95 latency, 429 rate) and health check. Dashboard panels and alert thresholds.",
            "status": "done",
            "testStrategy": "CI runs integration tests on each commit. K6/Gatling load tests in staging. Verify metrics exposed (Prometheus/OpenTelemetry) and alerts fire on induced failures."
          }
        ]
      },
      {
        "id": 7,
        "title": "Payment page frontend refactor (dynamic, responsive, accessible)",
        "description": "Rebuild payment page to dynamically load options per selected booster club, remove checks, and ensure mobile UX.",
        "details": "- Remove paper check section.\n- HTML: club selector <select>, sections for Zelle (img), Stripe buttons (3 types), instructions.\n- JS: On club change, fetch /api/booster-clubs/:id/payment-options, update DOM.\n- Accessibility: proper labels, alt text for QR (“Zelle QR code for {club}”), focus management, keyboard nav, color contrast AA.\n- Responsive: CSS grid/flex, clamp() for font sizes, images max-width: 320px on mobile; use srcset for 320/480/640 PNG variants.\n- Security: set rel=\"noopener\" on outbound links, noreferrer; data- attributes only; sanitize paymentInstructions via DOMPurify (2.5.7) with strict allowlist (p, br, strong, em, ul, li, a with href https only, target=_blank).\n- Performance: defer JS, inline critical CSS, lazy-load QR image with loading=\"lazy\".\n- Progressive enhancement: server-render basic list with noscript fallbacks where possible.",
        "testStrategy": "Unit tests with Jest + @testing-library/dom for DOM updates. Manual a11y tests with axe-core. Cross-browser (Chrome, Safari, Firefox, Edge) and device emulation. Verify under 3s load with Lighthouse on mobile. Ensure missing assets show friendly messages.",
        "priority": "high",
        "dependencies": [
          6
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Refactor HTML structure and remove check section",
            "description": "Rework the payment page markup to support dynamic club options, remove the paper check section, and provide semantic, accessible structure.",
            "dependencies": [],
            "details": "Implement a semantic layout using <form>, <section>, <label>, <select>, and <button>. Include a club selector <select> with an associated <label>, sections for Zelle (image container), Stripe (three button/link types), and payment instructions. Remove the paper check section entirely. Add proper accessible names and relationships for all interactive elements, and prepare noscript fallbacks for server-rendered basic content.",
            "status": "done",
            "testStrategy": "Manual DOM inspection for correct structure and absence of the check section. Validate semantic roles and label associations using axe-core and browser accessibility tree. Verify noscript fallback renders essential information when JS is disabled."
          },
          {
            "id": 2,
            "title": "Dynamic content loading and DOM updates via JS",
            "description": "Implement client-side logic to fetch and render payment options when the user selects a booster club.",
            "dependencies": [
              "7.1"
            ],
            "details": "On change of the club selector, fetch GET /api/booster-clubs/:id/payment-options. Update DOM for Zelle QR image, Stripe donation/membership/fees buttons, and instructions. Handle states: loading, success, disabled (isPaymentEnabled=false), missing assets (show friendly messages). Defer JS, use data- attributes only, and sanitize paymentInstructions using DOMPurify v2.5.7 with a strict allowlist (p, br, strong, em, ul, li, a with https-only href and target=_blank). Set rel=\"noopener noreferrer\" on outbound links.",
            "status": "done",
            "testStrategy": "Unit tests with Jest + @testing-library/dom to verify DOM updates for enabled/disabled/missing data cases. Mock fetch to return various payloads and network errors. Confirm rel attributes and sanitized instructions are applied."
          },
          {
            "id": 3,
            "title": "Accessibility implementation and focus/keyboard management",
            "description": "Ensure the page meets accessibility requirements including labels, alt text, focus handling, keyboard navigation, and color contrast AA.",
            "dependencies": [
              "7.1",
              "7.2"
            ],
            "details": "Add accessible labels for all controls. Set QR image alt text to “Zelle QR code for {club}”. Manage focus on dynamic updates: move focus to an ARIA live region summary or the first updated actionable element. Support full keyboard navigation and visible focus states. Use ARIA live regions for status messages (loading, errors). Ensure color contrast meets WCAG AA.",
            "status": "done",
            "testStrategy": "Run axe-core and manual keyboard-only navigation checks. Use screen reader smoke tests for announcements. Validate contrast with tooling and confirm focus order and visibility after dynamic content changes."
          },
          {
            "id": 4,
            "title": "Responsive layout, images, and performance optimizations",
            "description": "Implement responsive CSS and image handling with mobile-first performance improvements.",
            "dependencies": [
              "7.1"
            ],
            "details": "Use CSS Grid/Flex for layout; apply clamp() for font sizes. Constrain images to max-width: 320px on small viewports. Provide srcset for Zelle QR PNG variants (320/480/640). Add loading=\"lazy\" to QR images. Inline critical CSS and defer JS. Ensure cross-browser compatibility and provide fallbacks where needed.",
            "status": "done",
            "testStrategy": "Test across Chrome, Safari, Firefox, Edge and device emulators. Verify image selection via srcset at different DPRs and widths. Measure Lighthouse mobile performance to ensure <3s load. Validate lazy-loading behavior and no layout shifts."
          },
          {
            "id": 5,
            "title": "Progressive enhancement, security hardening, and error states",
            "description": "Finalize progressive enhancement strategy, enforce front-end security measures, and handle degraded scenarios gracefully.",
            "dependencies": [
              "7.2",
              "7.3",
              "7.4"
            ],
            "details": "Server-render a basic list of payment options as fallback where possible and include <noscript> messaging for users without JS. Enforce rel=\"noopener noreferrer\" on all outbound links. Restrict content updates to sanitized fields only. Display user-friendly messages for missing images or links. Log client-side errors minimally without leaking sensitive data.",
            "status": "done",
            "testStrategy": "Disable JS to verify server-rendered fallbacks and noscript messages. Security review to confirm no inline event handlers, only data- attributes, and sanitized instructions. Simulate missing assets and network failures to confirm graceful UI and accessible announcements."
          }
        ]
      },
      {
        "id": 8,
        "title": "Admin dashboard payment management UI",
        "description": "Add admin UI to upload QR codes, edit Stripe links, toggle enablement, and manage instructions.",
        "details": "- Vanilla JS admin page/module within existing dashboard.\n- Features: search/select club; form fields for three Stripe links; textarea for instructions; isPaymentEnabled toggle; QR upload with preview and replace; display current QR path.\n- Bulk import/export: CSV export of payment fields; CSV import validates headers and previews changes. Uses endpoints from tasks 3,5.\n- Client-side validation: URL patterns, required when enabling payments.\n- UX: form autosave debounce; confirm dialogs; error toasts.\n- Security: admin-only route guard; CSRF token if cookie auth; no inline JS.\n- Logging: call will include X-Request-ID for audit correlation.",
        "testStrategy": "Cypress E2E: admin can upload QR and see preview; update links; toggle enablement; export/import CSV with validation errors highlighted. Negative tests for invalid URLs and oversized images.",
        "priority": "high",
        "dependencies": [
          3,
          5
        ],
        "status": "in-progress",
        "subtasks": [
          {
            "id": 1,
            "title": "Admin payments UI layout and form scaffolding",
            "description": "Create the vanilla JS admin page/module within the existing dashboard with all required fields and controls.",
            "dependencies": [],
            "details": "Implement club search/select; text inputs for stripeDonationLink, stripeMembershipLink, stripeFeesLink; textarea for paymentInstructions; checkbox/toggle for isPaymentEnabled; QR upload input with image preview and replace; readonly display of current zelleQrCodePath. Use semantic HTML with labels and ARIA where needed. No inline JS; module pattern with namespaced events.",
            "status": "done",
            "testStrategy": "Manual UI check: all elements render and are accessible via keyboard and labels announce correctly. Validate that current values hydrate from fetched data when a club is selected."
          },
          {
            "id": 2,
            "title": "Data fetching, autosave, and validation",
            "description": "Wire club selection to load/save payment fields with debounced autosave and client-side validation.",
            "dependencies": [
              "8.1"
            ],
            "details": "On club change, GET existing values via endpoints from tasks 3,5; populate form. Implement debounced autosave (e.g., 800ms) on field changes with optimistic UI and error toasts. Validate URL patterns for Stripe links; when isPaymentEnabled is true, require all required fields. Confirm dialogs for destructive/revert actions. Include X-Request-ID header on all requests and propagate from server response if present.",
            "status": "pending",
            "testStrategy": "Unit tests for validation rules and debounce. Simulate successful and failing saves; verify error toasts and rollback. Confirm required fields enforced only when enabling payments."
          },
          {
            "id": 3,
            "title": "QR code upload with preview and replace",
            "description": "Implement secure image upload flow for Zelle QR with client-side constraints and preview/replace UX.",
            "dependencies": [
              "8.1",
              "8.2"
            ],
            "details": "Before upload, validate file type (PNG/JPEG), size limit (e.g., 2–5MB), and dimensions if available. Show preview using object URL; allow replace/cancel before commit. On confirm, POST to upload endpoint, then update zelleQrCodePath display and invalidate preview URL. Handle oversized/invalid images with clear toasts.",
            "status": "pending",
            "testStrategy": "Cypress E2E: upload valid QR shows preview and persists; attempt oversized/invalid type shows validation error and prevents upload. Replace flow updates preview and stored path."
          },
          {
            "id": 4,
            "title": "Bulk CSV export/import with header validation and change preview",
            "description": "Enable CSV export of payment fields and safe import with header checks, diff preview, and per-row validation.",
            "dependencies": [
              "8.2"
            ],
            "details": "Export: generate CSV for selected/all clubs including isPaymentEnabled, stripe links, paymentInstructions, zelleQrCodePath. Import: parse client-side, validate required headers, show table of proposed changes highlighting invalid fields (e.g., bad URLs, missing required when enabling). Allow confirm to POST batch to API (tasks 3,5). Provide progress, partial failure reporting, and undo link if supported.",
            "status": "pending",
            "testStrategy": "Cypress: export triggers download with correct headers. Import valid CSV shows preview and commits. Invalid headers blocked with clear error. Row-level invalid URLs highlighted and prevented from submission."
          },
          {
            "id": 5,
            "title": "Security, routing guard, CSRF, logging, and UX polish",
            "description": "Harden the module with admin-only access, CSRF handling, non-inline JS/CSP compliance, and consistent toasts/confirm modals.",
            "dependencies": [
              "8.2",
              "8.3",
              "8.4"
            ],
            "details": "Add route guard to restrict access to admin roles; fetch and include CSRF token for cookie-auth flows; ensure all requests include X-Request-ID and surface it in error details for audit correlation. Centralize toast/confirm components, focus management, and error states. Verify no inline scripts/styles; adhere to CSP. Instrument basic telemetry for saves/uploads/imports.",
            "status": "pending",
            "testStrategy": "Integration/E2E: non-admin blocked. CSRF failure simulated returns 403 and shows actionable message. Network inspector confirms X-Request-ID on requests. Axe-core pass on dialogs and toasts. CSP report shows no violations."
          }
        ]
      },
      {
        "id": 9,
        "title": "API authentication/authorization hardening",
        "description": "Ensure admin-only endpoints require strong auth and RBAC; add rate limiting and audit logging.",
        "details": "- Middleware: verify JWT/session; check role === 'admin'.\n- Add rate-limiter-flexible per IP and per user for admin routes (e.g., 100/hour).\n- Pino child logger adds userId, ip, route.\n- Return 401/403 appropriately; no sensitive data in error messages.\n- Add CSRF protection with csurf if cookie-based auth; otherwise require SameSite=strict cookies and double-submit token.\n- Security headers via helmet: HSTS, frameguard DENY, contentSecurityPolicy default-src 'self'; upgrade-insecure-requests.\n- Implement audit logger helper used in tasks 3 and 5.",
        "testStrategy": "Auth integration tests: unauthorized blocked; authorized allowed. Role downgrade test. CSRF test via simulated cross-site POST. Confirm logs contain audit entries without PII leakage.",
        "priority": "high",
        "dependencies": [
          5,
          3,
          1
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement strong admin auth middleware with RBAC",
            "description": "Create centralized middleware that verifies JWT or session, enforces TLS-only cookies when session-based, and checks role === 'admin' for admin-only routes.",
            "dependencies": [],
            "details": "• Validate and decode JWTs (issuer/audience, signature, exp) or verify server-side sessions.\n• Enforce RBAC: deny if user missing or role !== 'admin'.\n• Ensure HTTPS-only transport and secure cookie flags (Secure, HttpOnly, SameSite=strict for session-based flows).",
            "status": "pending",
            "testStrategy": "Integration tests: unauthorized returns 401; authenticated non-admin returns 403; admin allowed. Verify cookies have Secure/HttpOnly/SameSite=strict when applicable."
          },
          {
            "id": 2,
            "title": "Add rate limiting for admin endpoints (per IP and per user)",
            "description": "Use rate-limiter-flexible to enforce 100/hour per IP and per authenticated user on admin routes.",
            "dependencies": [
              "9.1"
            ],
            "details": "• Configure two limiters: per-IP and per-userId (fallback to IP for unauthenticated requests).\n• Use a shared store (e.g., Redis) in production to avoid bypass across instances.\n• Return 429 with generic message; include Retry-After.\n• Exempt internal health checks.",
            "status": "pending",
            "testStrategy": "Simulate bursts to hit limits; confirm 429 and headers. Verify limits apply distinctly per user and per IP."
          },
          {
            "id": 3,
            "title": "Integrate structured logging and audit trail for admin actions",
            "description": "Create a Pino child logger for requests that adds userId, ip, and route; implement an audit logger helper used by admin flows.",
            "dependencies": [
              "9.1"
            ],
            "details": "• pino-http middleware with redaction for Authorization, cookies, tokens.\n• Child logger fields: userId (or anon), ip, route, requestId.\n• Audit helper: write append-only entries (actorId, action, resource, before/after, timestamp) without PII leakage.\n• Hook audit logger into Tasks 3 and 5 flows via shared helper.",
            "status": "pending",
            "testStrategy": "Trigger admin updates and uploads; verify audit entries created and request logs contain context fields with no sensitive data."
          },
          {
            "id": 4,
            "title": "Harden responses, CSRF defenses, and security headers",
            "description": "Return proper 401/403 with non-sensitive errors; add CSRF protection based on auth mode; enforce Helmet security headers.",
            "dependencies": [
              "9.1"
            ],
            "details": "• Error handling: standardized problem+json, no stack or secrets to clients; 401 for unauthenticated, 403 for forbidden.\n• If cookie-based auth: use csurf with double-submit or same-site strict; otherwise require double-submit token with SameSite=strict cookies.\n• Helmet: HSTS, frameguard DENY, CSP default-src 'self', upgrade-insecure-requests.\n• Disable X-Powered-By; set no-cache on sensitive endpoints as needed.",
            "status": "pending",
            "testStrategy": "CSRF test via cross-site POST simulation; verify blocked. Check headers present on responses. Confirm error payloads contain no sensitive fields."
          },
          {
            "id": 5,
            "title": "End-to-end security tests and dependency hardening",
            "description": "Add automated auth/role downgrade tests, rate limit tests, and dependency/transport hardening checks across admin endpoints.",
            "dependencies": [
              "9.2",
              "9.3",
              "9.4"
            ],
            "details": "• E2E tests: unauthorized blocked, authorized allowed; attempt role downgrade/jwt tampering; confirm 401/403.\n• Load tests to validate rate limiter behavior under concurrency.\n• Verify TLS-only access in staging/production and cookie attributes.\n• Add npm audit/dep check and basic DAST on admin routes.",
            "status": "pending",
            "testStrategy": "CI suite runs integration and E2E tests; assert logs contain audit entries; verify no PII leakage; capture metrics on DB latency for future dashboards."
          }
        ]
      },
      {
        "id": 10,
        "title": "Data validation and sanitization layer",
        "description": "Centralize input validation for all payment-related endpoints and sanitize output for XSS prevention.",
        "details": "- Build zod schemas: PaymentLinksSchema, PaymentInstructionsSchema (allow limited markdown/HTML), ClubIdParam.\n- Backend sanitization: sanitize-html 2.13 with strict allowedTags/Attributes. Strip scripts and event handlers. Normalize whitespace and trim.\n- Output encoding: ensure JSON serialization only; set content-type, no HTML injection. Escape text in server-rendered templates if any.\n- Add Jest unit tests for edge cases.\n- Ensure logs redact user-supplied fields.",
        "testStrategy": "Run unit tests with crafted XSS payloads. Verify sanitization removes scripts. Fuzz test with strings >10k chars. Verify response headers include X-Content-Type-Options nosniff.",
        "priority": "high",
        "dependencies": [
          5,
          6,
          9
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Zod schemas for payment inputs",
            "description": "Create centralized Zod schemas: PaymentLinksSchema, PaymentInstructionsSchema (support limited markdown/HTML), and ClubIdParam for all payment-related endpoints.",
            "dependencies": [],
            "details": "Implement strict schemas with trimming and normalization. Payment links must match allowlisted Stripe domains and https. PaymentInstructionsSchema allows a constrained subset of markdown/HTML tokens to align with backend sanitization. ClubIdParam validates UUID and coerces types where needed. Export parse/validate helpers and types for reuse across routes.",
            "status": "pending",
            "testStrategy": "Unit test with valid/invalid URLs (allowlist regex), disallow javascript: and data: schemes, and boundary cases (empty strings, excessively long inputs, unicode). Fuzz strings >10k chars to ensure performance and no crashes."
          },
          {
            "id": 2,
            "title": "Implement backend sanitization pipeline",
            "description": "Wire sanitize-html 2.13 with strict allowedTags/allowedAttributes and global stripping of scripts and event handlers. Normalize whitespace and trim.",
            "dependencies": [
              "10.1"
            ],
            "details": "Create a sanitizeContent utility enforcing a minimal, explicit allowlist (e.g., a, strong, em, ul, ol, li, p, br) and safe attributes (href with https only, rel=noopener noreferrer). Remove on* event handlers, style, iframe, script. Normalize whitespace and trim output. Integrate into request handling after validation and before persistence/response.",
            "status": "pending",
            "testStrategy": "Feed canonical XSS payloads (script tags, onerror, href=javascript:, data: URLs, SVG payloads). Verify all are removed or neutralized. Confirm allowed tags/attributes remain. Snapshot sanitized output for determinism."
          },
          {
            "id": 3,
            "title": "Enforce output encoding and security headers",
            "description": "Ensure all payment APIs respond with JSON only, correct content-type, and safe server-rendered escaping if present. Add X-Content-Type-Options nosniff.",
            "dependencies": [
              "10.2"
            ],
            "details": "Set res.type('application/json; charset=utf-8') and ensure JSON serialization only. For any server-rendered templates, escape user text and avoid raw injection. Add Helmet config to set noSniff and reinforce MIME sniffing protections. Prohibit HTML in API responses.",
            "status": "pending",
            "testStrategy": "Integration tests verifying response headers (Content-Type, X-Content-Type-Options=nosniff). Attempt to inject HTML into fields and confirm it is returned as inert JSON strings, not rendered HTML."
          },
          {
            "id": 4,
            "title": "Redact user-supplied fields in logs",
            "description": "Configure logger to sanitize or omit sensitive and user-supplied fields across request/response and error logs.",
            "dependencies": [
              "10.1",
              "10.2"
            ],
            "details": "Implement a pino redaction strategy for paymentInstructions, stripe*Link fields, and any free-text inputs. Ensure request bodies and errors use redaction before logging. Add structured log keys with [REDACTED] markers and verify no raw HTML/markdown is logged.",
            "status": "pending",
            "testStrategy": "Automated tests sending payloads with XSS and PII; assert logs contain redacted placeholders. Manually inspect log output during local runs."
          },
          {
            "id": 5,
            "title": "Jest test suite for validation, sanitization, and resilience",
            "description": "Add comprehensive unit tests and targeted integration tests covering edge cases, fuzzing, and regression scenarios.",
            "dependencies": [
              "10.1",
              "10.2",
              "10.3",
              "10.4"
            ],
            "details": "Create Jest suites: zod-validation.spec.ts (URLs, UUIDs, long inputs), sanitize-html.spec.ts (XSS payload corpus, markdown/HTML allowlist), headers-and-encoding.spec.ts (content-type, nosniff), logging-redaction.spec.ts. Include performance guardrails for large inputs.",
            "status": "pending",
            "testStrategy": "Use curated XSS test cases and fuzz strings >10k chars. Assert scripts and event handlers removed, links normalized, headers set, and logs redacted. Add regression tests for any discovered issues."
          }
        ]
      },
      {
        "id": 11,
        "title": "Performance optimization and caching",
        "description": "Optimize images, API responses, and apply caching strategies to meet <3s load and mobile performance.",
        "details": "- QR images: generate 320/480/640 variants via sharp at upload/extract time; use <img srcset>.\n- Compression: enable gzip/br on server; ensure Vercel static compression.\n- Caching: set immutable cache for QR PNGs; API responses cache 5 minutes with ETag; client-side caching via stale-while-revalidate strategy in fetch wrapper if applicable.\n- DB: add indexes on is_payment_enabled and name; use SELECT specific fields only.\n- Lazy load non-critical admin scripts; split admin bundle.\n- Lighthouse budget: TTI < 2.5s on 4G throttling.",
        "testStrategy": "Measure with Lighthouse and WebPageTest. Validate response headers. Run k6 load test for API p95 < 200ms at 50 RPS. Confirm image variant chosen per DPR/viewport.",
        "priority": "medium",
        "dependencies": [
          3,
          4,
          6,
          7
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement responsive QR image pipeline with srcset",
            "description": "Generate 320/480/640 PNG variants at upload/extract time and serve with <img srcset> for DPR/viewport-aware selection.",
            "dependencies": [],
            "details": "Use sharp to output 320/480/640 widths, strip metadata, and store predictable paths. Update frontend to emit <img src=\"...-480.png\" srcset=\"...-320.png 320w, ...-480.png 480w, ...-640.png 640w\" sizes=\"(max-width: 640px) 100vw, 640px\">. Ensure accessibility (alt text) and high contrast QR images for reliable scanning.",
            "status": "pending",
            "testStrategy": "Manually verify the correct variant loads at different DPR/viewport via DevTools. Confirm QR readability across devices and that EXIF is removed. Lighthouse: image element uses srcset; network panel shows smallest sufficient file."
          },
          {
            "id": 2,
            "title": "Enable and validate HTTP compression (gzip/br)",
            "description": "Configure server and Vercel static compression for Brotli/gzip to reduce transfer size for HTML/CSS/JS/API responses.",
            "dependencies": [],
            "details": "Enable compression middleware or edge config with priority for Brotli (br) and fallback to gzip. Verify cache compatibility (Vary: Accept-Encoding). Avoid double-compressing already compressed assets (images, fonts).",
            "status": "pending",
            "testStrategy": "Use curl -I and DevTools to confirm Content-Encoding: br/gzip on text assets. Compare transferred sizes before/after. Lighthouse transfer size savings should reflect compression."
          },
          {
            "id": 3,
            "title": "Set caching headers for static QR PNGs and API responses",
            "description": "Apply immutable caching for QR PNGs and short-lived cache with ETag for APIs; add client stale-while-revalidate.",
            "dependencies": [
              "11.1",
              "11.2"
            ],
            "details": "Static PNGs: Cache-Control: public, max-age=31536000, immutable with content-hashed URLs when possible. API: Cache-Control: public, max-age=300, stale-while-revalidate=60; add ETag/If-None-Match handling for 304s. Client fetch wrapper: use SWR pattern to serve cached data and revalidate in background.",
            "status": "pending",
            "testStrategy": "Validate response headers in DevTools. Hit API twice to observe 304 with ETag. Confirm client returns cached data immediately and refreshes. WebPageTest: verify cache hits on repeat view."
          },
          {
            "id": 4,
            "title": "Database performance tuning for payment queries",
            "description": "Add targeted indexes and narrow SELECTs to reduce latency of payment-related endpoints.",
            "dependencies": [],
            "details": "Create btree indexes on is_payment_enabled and name. Update queries to SELECT only required columns for listing/details. Analyze query plans and ensure index usage. Consider covering indexes if needed.",
            "status": "pending",
            "testStrategy": "EXPLAIN ANALYZE before/after to confirm index scans. k6 load test at 50 RPS: p95 < 200ms. Monitor DB metrics (cache hit ratio, slow query log)."
          },
          {
            "id": 5,
            "title": "Frontend performance: lazy-load non-critical admin scripts and bundle split",
            "description": "Defer non-critical admin JS, split bundles, and ensure fast TTI under mobile conditions.",
            "dependencies": [
              "11.3",
              "11.4"
            ],
            "details": "Use dynamic import() for rarely used admin modules; mark scripts as defer; inline critical CSS if minimal. Audit third-party scripts. Ensure no render-blocking resources. Configure code splitting and long-term caching for chunks.",
            "status": "pending",
            "testStrategy": "Lighthouse on 4G throttling: TTI < 2.5s and overall load < 3s. Measure JS execution time and main-thread blocking. Verify chunks load on demand and that initial bundle size decreases."
          }
        ]
      },
      {
        "id": 12,
        "title": "Comprehensive testing suite",
        "description": "Add unit, integration, E2E, and security tests covering API, frontend payment page, and admin flows.",
        "details": "- Unit: Jest for validators, controllers, utilities.\n- Integration: supertest for Express endpoints (CRUD, auth failures, caching headers).\n- E2E: Cypress for payment page and admin flows.\n- Security: dependency audit (npm audit, snyk if available), basic DAST with OWASP ZAP against staging.\n- Cross-browser grid: Playwright against Chrome/Firefox/WebKit for critical paths.\n- Mobile responsiveness snapshots with Percy/Chromatic-like visual tests or Cypress screenshots.\n- CI: GitHub Actions with matrix Node 20/22; cache pnpm; run on PRs, block merges on failures.",
        "testStrategy": "Green suite in CI. Coverage threshold: 80% statements/branches for new code. ZAP baseline scan has no high/critical. Cross-browser tests pass. Manual device tests on iOS/Android for QR scan and Stripe link navigation.",
        "priority": "high",
        "dependencies": [
          7,
          8,
          5,
          6,
          10,
          11
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up unit test framework and coverage thresholds",
            "description": "Configure Jest for validators, controllers, and utilities with 80% coverage thresholds for statements and branches on new/changed code.",
            "dependencies": [],
            "details": "Add Jest config, ts-jest/babel if needed, and coverage thresholds. Write sample tests for validators, controllers, and utility functions. Ensure deterministic seeds and test data builders. Add npm scripts: test:unit, test:watch, test:coverage.",
            "status": "pending",
            "testStrategy": "Run npm run test:unit with coverage gates enforced. Verify failing coverage blocks PR merges via CI status."
          },
          {
            "id": 2,
            "title": "Implement API integration tests with Supertest",
            "description": "Create Supertest suites for Express endpoints covering CRUD, auth failures, and response caching headers.",
            "dependencies": [
              "12.1"
            ],
            "details": "Spin up app with in-memory or test DB, seed fixtures, and test routes including positive/negative cases and header assertions (Cache-Control/ETag). Add npm script: test:integration.",
            "status": "pending",
            "testStrategy": "Run npm run test:integration; ensure tests assert status codes, payload shapes, and headers. Confirm auth failure paths return 401/403 as expected."
          },
          {
            "id": 3,
            "title": "Add E2E tests for payment and admin flows",
            "description": "Use Cypress for E2E coverage of payment page (Zelle QR display, Stripe links) and admin workflows (QR upload, link edits, enablement toggles).",
            "dependencies": [
              "12.2"
            ],
            "details": "Create Cypress spec files for user and admin paths with fixtures and network stubbing where appropriate. Include mobile viewport tests and visual snapshots for responsiveness (Percy/Chromatic-like or Cypress screenshots). Add npm script: test:e2e.",
            "status": "pending",
            "testStrategy": "Run Cypress in headed/CI modes. Validate UI state updates, accessibility checks (axe), and visual diffs for mobile snapshots. Ensure specs are idempotent."
          },
          {
            "id": 4,
            "title": "Security scans and cross-browser grid",
            "description": "Integrate dependency audits (npm audit, Snyk if available), OWASP ZAP baseline scan against staging, and Playwright cross-browser tests for critical paths.",
            "dependencies": [
              "12.3"
            ],
            "details": "Add npm scripts: audit, audit:fix, zap:baseline, test:xbrowser. Configure Playwright to run on Chromium, Firefox, and WebKit for checkout-critical flows. Define ZAP baseline to fail on high/critical findings.",
            "status": "pending",
            "testStrategy": "CI runs audits and ZAP; build fails on high/critical. Playwright tests assert critical flow parity across browsers."
          },
          {
            "id": 5,
            "title": "CI pipeline with GitHub Actions matrix and PR gating",
            "description": "Create GitHub Actions workflows to run unit, integration, E2E, security, and cross-browser tests with Node 20/22 matrix, pnpm cache, and required checks on PRs.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.3",
              "12.4"
            ],
            "details": "Add .github/workflows/node-ci.yml with actions/checkout, setup-node matrix (20.x, 22.x), pnpm cache, and jobs for unit/integration/E2E/Playwright. Add separate job/step for npm audit and optional Snyk; include ZAP baseline against staging. Configure PR-required checks to block merges on failures.",
            "status": "pending",
            "testStrategy": "Open a PR to trigger the workflow; verify all jobs run on the matrix and fail appropriately when tests, coverage, or scans fail."
          }
        ]
      },
      {
        "id": 13,
        "title": "Logging, monitoring, and audit dashboards",
        "description": "Implement structured logging, error tracking, and an admin-visible audit trail view.",
        "details": "- Use pino-http for request logs; redact Authorization, cookies, tokens, links if necessary.\n- Centralize error handler to standardize problem+json.\n- Expose admin page listing PaymentAudit records with filters by club, actor, date.\n- Integrate with existing monitoring (Vercel, Neon). Optional Sentry SDK if available.\n- Healthcheck endpoint /healthz including DB check.",
        "testStrategy": "Force errors to confirm logs and stack traces appear. Verify audit list shows entries after edits. Healthcheck returns 200 and includes DB latency metric.",
        "priority": "medium",
        "dependencies": [
          5,
          6,
          9,
          12
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement pino-http with sensitive data redaction and healthcheck auto-logging skip",
            "description": "Add structured HTTP request/response logging using pino-http with redaction for Authorization, cookies, tokens, and potentially links; skip auto-logging for /healthz and static assets.",
            "dependencies": [],
            "details": "Install and configure pino and pino-http. Set redact: ['headers.authorization', 'headers.cookie', 'headers.set-cookie', 'req.headers.authorization', 'req.headers.cookie', 'req.headers.set-cookie', 'query.token', 'body.token', 'body.password', 'body.link']. Configure autoLogging.ignore for /healthz and static assets. Use minimal serializers for req/res to include method, url, id, statusCode, responseTime. Provide pino-pretty transport in development only.",
            "status": "pending",
            "testStrategy": "Hit various endpoints and confirm JSON logs redact sensitive fields and include requestId. Verify /healthz is not logged while other endpoints are. Check dev pretty output and prod JSON."
          },
          {
            "id": 2,
            "title": "Centralized error handler with RFC 7807 problem+json",
            "description": "Create a single Express error-handling middleware that normalizes errors into application/problem+json responses and logs with stack traces via pino.",
            "dependencies": [
              "13.1"
            ],
            "details": "Implement error classes (e.g., ValidationError with status 400, NotFoundError 404) and map to problem+json fields: type, title, status, detail, instance, and optional extensions. Ensure content-type application/problem+json; charset=utf-8. Log using req.log.error with err, requestId, and safe context. Include zod validation integration to produce structured details.",
            "status": "pending",
            "testStrategy": "Force errors (throw new Error, validation fail) and verify standardized problem+json body and appropriate HTTP status. Confirm logs include error.stack and requestId and redact sensitive fields."
          },
          {
            "id": 3,
            "title": "Admin audit trail UI listing PaymentAudit with filters",
            "description": "Expose an admin page that lists PaymentAudit records with server-side pagination and filters by club, actor, and date range.",
            "dependencies": [
              "13.2"
            ],
            "details": "Backend: implement GET /admin/audit?clubId=&actor=&from=&to=&page=&limit=. Query PaymentAudit with indexes from Task 2, return JSON with total, items. Frontend: vanilla JS UI in admin dashboard to render table (createdAt, club, actor, action), inputs for filters, and debounced fetch. Preserve access control (admin RBAC). Ensure logs include audit query timings.",
            "status": "pending",
            "testStrategy": "Seed audit data; verify filters narrow results correctly and pagination works. Confirm access is restricted to admin. After editing payments (from Task 8), entries appear in list."
          },
          {
            "id": 4,
            "title": "Healthcheck endpoint with DB connectivity and latency metric",
            "description": "Add /healthz that reports service status and verifies database round-trip with latency measurement.",
            "dependencies": [
              "13.1"
            ],
            "details": "Implement GET /healthz returning 200 JSON: { status: 'ok', time, db: { status, latencyMs, version } }. Perform lightweight SELECT 1 or SELECT now(); capture latency with process.hrtime. Return non-200 and problem+json if DB fails. Exclude from pino autoLogging per Subtask 13.1.",
            "status": "pending",
            "testStrategy": "With DB up, /healthz returns 200 and numeric latency. Induce DB failure (wrong creds or terminate connection) and verify non-200 with problem+json and appropriate log entry."
          },
          {
            "id": 5,
            "title": "Monitoring integrations (Vercel/Neon) and optional Sentry SDK",
            "description": "Wire logs and metrics to existing platform monitors, surface runtime and DB health, and add optional Sentry error reporting if DSN configured.",
            "dependencies": [
              "13.1",
              "13.2",
              "13.4"
            ],
            "details": "Ensure Vercel log drains capture pino JSON; tag environment, commit SHA, and requestId. For Neon, enable query logging/connection metrics where permissible and include Neon connection ID in logs if available. Add Sentry SDK (Node/Express) gated by SENTRY_DSN; capture exceptions in error middleware while avoiding PII. Document dashboards/alerts and ensure log correlation fields (traceId if available).",
            "status": "pending",
            "testStrategy": "Trigger sample errors to verify appearance in Vercel logs and Sentry (when DSN set). Validate Neon connectivity metrics visible. Confirm log entries include env and requestId for correlation."
          }
        ]
      },
      {
        "id": 14,
        "title": "Deployment pipeline and environment configuration",
        "description": "Set up environments, secrets, and automated deployments with safe migrations.",
        "details": "- Envs: DATABASE_URL (Neon), STRIPE_LINK_DOMAIN_ALLOWLIST (buy.stripe.com,donate.stripe.com), ADMIN_JWT_ISSUER/AUDIENCE, NODE_ENV, LOG_LEVEL.\n- Vercel project config: build output for static assets; API routes deployment or Node server. Use vercel env for secrets.\n- DB migrations run via prisma migrate deploy on deploy.\n- Blue/green or canary if supported; otherwise staged rollout.\n- Backups: Neon PITR enabled. Rollback plan documented.",
        "testStrategy": "Deploy to staging automatically on main. Verify migrations applied. Smoke tests pass. Rollback test by reverting commit and re-deploying.",
        "priority": "medium",
        "dependencies": [
          2,
          1,
          12,
          11
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define environments and branch strategy on Vercel",
            "description": "Create Production, Preview, and a custom Staging environment with branch rules (e.g., main→staging, prod branch→production). Enable staged production deployments for manual promotion.",
            "dependencies": [],
            "details": "Configure Vercel Environments: Production, Preview, and a custom Staging. Set branch tracking so non-production branches deploy to Preview, main to Staging, and production branch to Production. Disable auto-assign custom production domains to allow verification before promotion; use Promote to Production after checks.",
            "status": "pending",
            "testStrategy": "Push to feature branch: verify Preview URL created. Push to main: verify Staging deployment and domain mapping. Push to prod branch: verify staged production deployment without domain, then promote and confirm traffic switch."
          },
          {
            "id": 2,
            "title": "Provision and scope environment variables and secrets",
            "description": "Create and scope all env vars (DATABASE_URL, STRIPE_LINK_DOMAIN_ALLOWLIST, ADMIN_JWT_ISSUER/AUDIENCE, NODE_ENV, LOG_LEVEL) per environment; pull Development vars locally via CLI.",
            "dependencies": [
              "14.1"
            ],
            "details": "Add env vars in Vercel Project Settings with environment scoping (Production, Preview, Staging/Custom). For local dev, use vercel env pull to .env.local. Ensure no secrets in repo; use NEXT_PUBLIC prefix only for intended client exposure. Consider importing variables from Production into Staging, then override as needed.",
            "status": "pending",
            "testStrategy": "Run vercel env pull and ensure .env.local populated. Validate each deployment can read all required env vars via /healthz or a diagnostics log."
          },
          {
            "id": 3,
            "title": "Configure Vercel project (build, output, functions)",
            "description": "Add vercel.json to set buildCommand/outputDirectory and functions config for API routes or Node server; ensure static asset output is correctly served.",
            "dependencies": [
              "14.1",
              "14.2"
            ],
            "details": "Create vercel.json with schema, buildCommand (e.g., next build), outputDirectory if using static export, and functions settings (memory, regions, runtime) for API routes. Configure rewrites/headers as needed. Ensure compatibility with API routes or custom Node server, and align with project’s build output for static assets.",
            "status": "pending",
            "testStrategy": "Trigger Preview deploy and confirm build logs use specified buildCommand. Verify static assets served and API routes respond. Check headers/rewrites via curl."
          },
          {
            "id": 4,
            "title": "Automate safe database migrations in deploy pipeline",
            "description": "Run prisma migrate deploy during deployments; add pre-checks and gating to prevent breaking changes; document rollback using Neon PITR.",
            "dependencies": [
              "14.2",
              "14.3"
            ],
            "details": "Add a deployment step/command to run prisma migrate deploy on each deploy. Include a lightweight readiness check (e.g., run migrations before switching traffic) and ensure blue/green or staged rollout: verify on Staging/Preview before promotion. Document and script rollback: revert commit, redeploy, and if needed restore using Neon PITR; maintain backup and restore runbook.",
            "status": "pending",
            "testStrategy": "On Staging deploy, verify migration applied and app healthy. Simulate failure with a bad migration on Preview; confirm deployment blocked or rolled back. Execute a rollback drill restoring to a point-in-time and redeploy."
          },
          {
            "id": 5,
            "title": "Implement staged rollout and health verification gates",
            "description": "Set healthcheck endpoint and promotion gates; use canary/staged production where supported, otherwise manual staged promotion after smoke checks.",
            "dependencies": [
              "14.3",
              "14.4"
            ],
            "details": "Expose /healthz including DB check to verify readiness. For Production, create staged deployments not auto-assigned to domains; run smoke tests and database connectivity checks, then Promote to Production. If canary not available, document staged rollout with manual promotion and monitoring steps.",
            "status": "pending",
            "testStrategy": "Deploy a staged Production build, hit /healthz, run smoke test suite, then promote. Monitor logs/metrics for regressions; validate rollback by promoting previous deployment or redeploying previous commit."
          }
        ]
      },
      {
        "id": 15,
        "title": "Documentation, training, and handover",
        "description": "Create concise docs for admins and developers, including runbooks and security notes.",
        "details": "- Admin guide: how to upload QR, manage Stripe links, bulk import/export, troubleshooting invalid links.\n- Dev docs: API contracts, validation rules, migration steps, image pipeline, caching, logging, and audit.\n- Security: PCI scope statement (no card data stored; Stripe links only)[2][1]; checklist of controls; incident response playbook.\n- Add README updates and ADRs for key decisions.\n- Short video or GIF walkthroughs for admin UI.",
        "testStrategy": "Docs reviewed by a non-developer admin for clarity. Keep in repo; ensure links and screenshots accurate. Runbook dry-run by team member.",
        "priority": "low",
        "dependencies": [
          8,
          12,
          13,
          14
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Admin Guide and Runbooks",
            "description": "Produce concise admin-facing documentation and operational runbooks covering core workflows and issue resolution.",
            "dependencies": [],
            "details": "Document: uploading Zelle QR, managing Stripe donation/membership/fees links, bulk import/export, and troubleshooting invalid links. Include step-by-step procedures, prerequisites, screenshots, and a quick-reference runbook for common incidents (e.g., broken Stripe link, missing QR, cache not updating). Apply best practices: clear headings, audience-focused content, and structured troubleshooting sections.[1][2][3]",
            "status": "pending",
            "testStrategy": "Have a non-developer admin follow the guide to complete each task in a staging environment; collect time-to-complete and confusion points. Verify every screenshot and link. Dry-run the runbook with a team member and record results."
          },
          {
            "id": 2,
            "title": "Developer Documentation (APIs, Pipelines, and Ops)",
            "description": "Create developer-focused docs that cover contracts, data flows, and operational concerns for maintainability.",
            "dependencies": [],
            "details": "Include API contracts and examples, validation rules, database migration steps, image pipeline (sharp) flow, caching behavior and headers, logging (pino) conventions, and audit trail schema/usage. Add copy-paste-ready commands, code snippets, and examples. Organize by reference vs. how-to, with consistent formatting and cross-references.[2][3][5]",
            "status": "pending",
            "testStrategy": "Have a developer new to the project implement a small change using the docs only; measure setup time and errors. Lint examples and run sample requests to ensure accuracy."
          },
          {
            "id": 3,
            "title": "Security Notes and Incident Response",
            "description": "Publish a security section covering PCI scope, controls, and incident response playbook aligned to project realities.",
            "dependencies": [],
            "details": "Write PCI scope statement clarifying no cardholder data is stored; payments use Stripe-hosted links only. Provide a checklist of security controls (CSP, RBAC admin-only, input validation, logging redaction, rate limiting) and an incident response playbook with roles, triage steps, evidence collection, communication, and postmortem template. Highlight warnings/tips prominently.[2]",
            "status": "pending",
            "testStrategy": "Tabletop exercise: simulate a security incident (e.g., suspected link tampering) and walk through the playbook; record gaps and update. Peer review by security-minded engineer."
          },
          {
            "id": 4,
            "title": "Repository Docs: README and ADRs",
            "description": "Update repository-facing docs for discoverability and architectural traceability.",
            "dependencies": [],
            "details": "Revise README with system overview, setup, env variables, scripts, deployment process, and links to admin/dev/security docs. Add ADRs for key decisions (e.g., Stripe link approach, audit model, caching headers, image pipeline). Ensure consistent formatting and cross-linking; include a mini ToC.[3][4]",
            "status": "pending",
            "testStrategy": "Clone fresh and follow README to run app locally and in staging; confirm no missing steps. Review ADRs with stakeholders to validate decision records."
          },
          {
            "id": 5,
            "title": "Visual Walkthroughs and Final Review",
            "description": "Record short videos/GIFs for admin UI flows and perform end-to-end documentation QA before handover.",
            "dependencies": [],
            "details": "Create brief screen-recorded walkthroughs of admin tasks (upload QR, manage Stripe links, bulk import/export) and embed/link them in the admin guide. Ensure content is accessible and oriented to the admin audience.[1][2] Conduct a cross-doc review for consistency, up-to-date screenshots, and working links; add a changelog and doc ownership notes.",
            "status": "pending",
            "testStrategy": "Have an admin complete tasks using only videos/GIFs to validate clarity. Run a broken-link and spell check. Final sign-off from product and support leads."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-12T19:06:54.808Z",
      "updated": "2025-08-12T21:38:51.526Z",
      "description": "Tasks for feature-payment-system-enhancement context"
    }
  }
}